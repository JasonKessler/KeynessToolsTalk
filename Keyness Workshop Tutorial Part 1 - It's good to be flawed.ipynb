{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scattertext\n",
    "- Scattertext is a Python package for creating interactive scatterplots over language data. There is substantial code to produce keyness and dispersion metrics and visualizations. \n",
    "- It has been under development since 2016. I've written >99% of the code in the package. This is a passion project for me and absolutely not associated with my day job.\n",
    "- It has a permissive Apache 2.0 license.\n",
    "- http://www.github.com/jasonkessler/scattertext\n",
    "\n",
    "## Installation\n",
    "- Recommended: install conda (https://docs.conda.io/projects/conda/en/stable/user-guide/install/index.html#installing-conda-on-a-system-that-has-other-python-installations-or-packages)\n",
    "- Create a new virtual environment\n",
    " - `$ conda create -n st310 python=3.10`\n",
    "- Activate it\n",
    " - `$ soure activate st310`\n",
    "- Install spaCy\n",
    " - https://spacy.io/usage\n",
    "- Install scattertext\n",
    " - `$ pip3 install -U scattertext`\n",
    "- If you'd like to use UMAP\n",
    " - `$ pip3 install umap-learn`\n",
    "\n",
    "\n",
    "## Caveats\n",
    "- The documentation is vignette-based. Many features are undocumented. The code is still in beta. Breaking changes can be made at any time!\n",
    " - With this in mind, don't be afraid to look through the code, make changes, and get your hands dirty.\n",
    "- Test case coverage could be a lot higher. Breaking changes may have been made which didn't trigger test case failures.\n",
    "- The visualization framework is written in Javascript and D3 v4. Browsers do not consistently implement the same Javascript standard, and their implementations can shift version-to-version, etc. In other words, you may have to modify the Javascript code to fix your visualization.\n",
    "\n",
    "## Agenda\n",
    "- Introducing Scattertext\n",
    "\n",
    "### Part 1. Visualizing two categories\n",
    "\n",
    "- The Rotten Tomatoes Corpus\n",
    "- Creating text-based corpora\n",
    "- Counting terms\n",
    "- Visualizing term counts\n",
    "- How the visualization works\n",
    "- Customizing the visualization; text colors \n",
    "- Scoring terms\n",
    "- Visualizing term scores\n",
    "- Using scattertext to train Gensim word embeddings\n",
    "- Visualizing projections of word embeddings \n",
    "- Visualizing how similar words are used across-categories\n",
    "\n",
    "### Part 2. Visualizing multiple categories\n",
    "- The Arthur Conan Doyle corpus \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, json, re, sys, time, warnings, datetime, glob\n",
    "sys.path.insert(0, '../scattertext/')\n",
    "\n",
    "import scipy.stats as ss    \n",
    "import pandas as pd\n",
    "import scattertext as st\n",
    "import numpy as np\n",
    "import spacy\n",
    "import umap # Optional\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "assert st.version >= [0, 1, 17] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "_ = nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Rotten Tomatoes Movie Review Data Set (Pang and Lee 2002)\n",
    "\n",
    "We parse each review with spaCy. On a 2018 Macbook Pro, this takes about 31 seconds. The progress bar tells us it has processed documents. Reviews include polarity (positive or negative) and the name of the movie being reviewed.  4,866 reviews are retained after filtering for plot descriptions.\n",
    "\n",
    "Data set is from http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "References:\n",
    "* Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan, Thumbs up? Sentiment Classification using Machine Learning Techniques, Proceedings of EMNLP 2002.\n",
    "\n",
    "* Bo Pang and Lillian Lee, A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts, Proceedings of ACL 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2913f8f881c46cda11b67fad9c888bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5022 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_full_df = st.SampleCorpora.RottenTomatoes.get_data().assign(\n",
    "    category = lambda df: df.category.apply(\n",
    "        lambda x: {'rotten': 'Negative', 'fresh': 'Positive', 'plot': 'Plot'}[x]),\n",
    "    SpacyParse=lambda df: df.text.progress_apply(nlp)\n",
    ")\n",
    "movie_df = movie_full_df[lambda df: df.category.isin(['Negative', 'Positive'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe statistics of review word lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SpacyParse</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>2411.0</td>\n",
       "      <td>22.358772</td>\n",
       "      <td>9.772912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>2455.0</td>\n",
       "      <td>22.745010</td>\n",
       "      <td>9.955164</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SpacyParse   count       mean       std  min   25%   50%   75%   max\n",
       "category                                                            \n",
       "Negative    2411.0  22.358772  9.772912  2.0  15.0  22.0  29.0  58.0\n",
       "Positive    2455.0  22.745010  9.955164  2.0  15.0  22.0  29.0  59.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.groupby('category').apply(lambda gdf: gdf.SpacyParse.apply(len).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine a positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_name': 'abandon',\n",
       " 'text': 'Difficult to peg and just as hard to predict.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(movie_df[lambda df: df.category=='Positive'][['movie_name', 'text']].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>SpacyParse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/Abandon_2002.html</td>\n",
       "      <td>Gaghan captures the half-lit, sometimes creepy...</td>\n",
       "      <td>abandon</td>\n",
       "      <td>(Gaghan, captures, the, half, -, lit, ,, somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/Abandon_2002.html</td>\n",
       "      <td>A dark, dull thriller with a parting shot that...</td>\n",
       "      <td>abandon</td>\n",
       "      <td>(A, dark, ,, dull, thriller, with, a, parting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Positive</td>\n",
       "      <td>subjectivity_html/subj/2002/Abandon_2002.html</td>\n",
       "      <td>Difficult to peg and just as hard to predict.</td>\n",
       "      <td>abandon</td>\n",
       "      <td>(Difficult, to, peg, and, just, as, hard, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/Abandon_2002.html</td>\n",
       "      <td>Meandering and glacially paced, and often just...</td>\n",
       "      <td>abandon</td>\n",
       "      <td>(Meandering, and, glacially, paced, ,, and, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/Abandon_2002.html</td>\n",
       "      <td>The only thing worse than your substandard, ru...</td>\n",
       "      <td>abandon</td>\n",
       "      <td>(The, only, thing, worse, than, your, substand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/XXX_2002.html</td>\n",
       "      <td>Even in the summertime, the most restless youn...</td>\n",
       "      <td>xxx</td>\n",
       "      <td>(Even, in, the, summertime, ,, the, most, rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/XXX_2002.html</td>\n",
       "      <td>The pretensions -- and disposable story -- sin...</td>\n",
       "      <td>xxx</td>\n",
       "      <td>(The, pretensions, --, and, disposable, story,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/XXX_2002.html</td>\n",
       "      <td>Unrelentingly stupid.</td>\n",
       "      <td>xxx</td>\n",
       "      <td>(Unrelentingly, stupid, .)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/XXX_2002.html</td>\n",
       "      <td>It's got the brawn, but not the brains.</td>\n",
       "      <td>xxx</td>\n",
       "      <td>(It, 's, got, the, brawn, ,, but, not, the, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>Negative</td>\n",
       "      <td>subjectivity_html/subj/2002/XXX_2002.html</td>\n",
       "      <td>It's refreshing that someone understands the n...</td>\n",
       "      <td>xxx</td>\n",
       "      <td>(It, 's, refreshing, that, someone, understand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4866 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category                                       filename  \\\n",
       "156   Negative  subjectivity_html/subj/2002/Abandon_2002.html   \n",
       "157   Negative  subjectivity_html/subj/2002/Abandon_2002.html   \n",
       "158   Positive  subjectivity_html/subj/2002/Abandon_2002.html   \n",
       "159   Negative  subjectivity_html/subj/2002/Abandon_2002.html   \n",
       "160   Negative  subjectivity_html/subj/2002/Abandon_2002.html   \n",
       "...        ...                                            ...   \n",
       "5017  Negative      subjectivity_html/subj/2002/XXX_2002.html   \n",
       "5018  Negative      subjectivity_html/subj/2002/XXX_2002.html   \n",
       "5019  Negative      subjectivity_html/subj/2002/XXX_2002.html   \n",
       "5020  Negative      subjectivity_html/subj/2002/XXX_2002.html   \n",
       "5021  Negative      subjectivity_html/subj/2002/XXX_2002.html   \n",
       "\n",
       "                                                   text movie_name  \\\n",
       "156   Gaghan captures the half-lit, sometimes creepy...    abandon   \n",
       "157   A dark, dull thriller with a parting shot that...    abandon   \n",
       "158       Difficult to peg and just as hard to predict.    abandon   \n",
       "159   Meandering and glacially paced, and often just...    abandon   \n",
       "160   The only thing worse than your substandard, ru...    abandon   \n",
       "...                                                 ...        ...   \n",
       "5017  Even in the summertime, the most restless youn...        xxx   \n",
       "5018  The pretensions -- and disposable story -- sin...        xxx   \n",
       "5019                              Unrelentingly stupid.        xxx   \n",
       "5020            It's got the brawn, but not the brains.        xxx   \n",
       "5021  It's refreshing that someone understands the n...        xxx   \n",
       "\n",
       "                                             SpacyParse  \n",
       "156   (Gaghan, captures, the, half, -, lit, ,, somet...  \n",
       "157   (A, dark, ,, dull, thriller, with, a, parting,...  \n",
       "158   (Difficult, to, peg, and, just, as, hard, to, ...  \n",
       "159   (Meandering, and, glacially, paced, ,, and, of...  \n",
       "160   (The, only, thing, worse, than, your, substand...  \n",
       "...                                                 ...  \n",
       "5017  (Even, in, the, summertime, ,, the, most, rest...  \n",
       "5018  (The, pretensions, --, and, disposable, story,...  \n",
       "5019                         (Unrelentingly, stupid, .)  \n",
       "5020  (It, 's, got, the, brawn, ,, but, not, the, br...  \n",
       "5021  (It, 's, refreshing, that, someone, understand...  \n",
       "\n",
       "[4866 rows x 5 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine a negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_name': 'abandon',\n",
       " 'text': 'Gaghan captures the half-lit, sometimes creepy intimacy of college dorm rooms, a subtlety that makes the silly, over-the-top coda especially disappointing.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(movie_df[lambda df: df.category=='Negative'][['movie_name', 'text']].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a corpus object in Scattertext\n",
    "- The most straightforward way to visualize documents in Scattertext is to create a corpus object from a Pandas data frame. Each row corresponds to a single document, while columns indicate other data about each document. Scattertext has numerous classes available to represent corpora, but the one we will begin with is a `ParsedCorpus` generated by the `CorpusFromParsedDocuments` factory.\n",
    "- Typically, each document has a category about which Scattertext can generate various keyness metrics and visualizations. The columns containing the category and parse are passed as `parse_col` and `parsed_col`, respectively.\n",
    "- The corpus object contains feature representations of each document. These either be tokens that occur in the document (using a case-insensitive search) or other features, some of which are linked to character offsets or a searchable lexicon. These non-searchable features are called \"non_text\" features. For now, we'll generate simple token features. \n",
    "- To turn each document into a feature vector, we will use the `FlexibleNGrams` class. Here, we output all unigrams found in the spaCy parses, filtering out blank spaces. We also exclude terms used in less than 6 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_corpus = st.CorpusFromParsedDocuments(\n",
    "    movie_df,\n",
    "    category_col='category',\n",
    "    parsed_col='SpacyParse',\n",
    "    feats_from_spacy_doc=st.FlexibleNGrams(ngram_sizes=[1])\n",
    ").build().filter_out(\n",
    "    lambda x: len(x.strip()) < 1\n",
    ").remove_terms_used_in_less_than_num_docs(\n",
    "    threshold=6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll create on which inclues the plots, for use later\n",
    "unigram_corpus_full = st.CorpusFromParsedDocuments(\n",
    "    movie_full_df,\n",
    "    category_col='category',\n",
    "    parsed_col='SpacyParse',\n",
    "    feats_from_spacy_doc=st.FlexibleNGrams(ngram_sizes=[1])\n",
    ").build().filter_out(\n",
    "    lambda x: len(x.strip()) < 1\n",
    ").remove_terms_used_in_less_than_num_docs(\n",
    "    threshold=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of terms in corpus: 2083\n",
      "Number of reviews in corpus: 4866\n",
      "Number of categories in corpus: 2\n",
      "Categories in corpus: ['Negative', 'Positive']\n",
      "First five terms (features) in corpus: ['captures', 'the', 'half', '-', ',']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of terms in corpus:\", unigram_corpus.get_num_terms())\n",
    "print(\"Number of reviews in corpus:\", unigram_corpus.get_num_docs())\n",
    "print(\"Number of categories in corpus:\", unigram_corpus.get_num_categories())\n",
    "print(\"Categories in corpus:\", unigram_corpus.get_categories())\n",
    "print(\"First five terms (features) in corpus:\", unigram_corpus.get_terms()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics about terms in the corpus \n",
    "\n",
    "= We can retrieve the term-document matrix as a sparse matrix using the `get_term_doc_mat` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4866x2083 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 81219 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = unigram_corpus.get_term_doc_mat()\n",
    "tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TermRankers: objects used to collect category-level metrics for downstream use\n",
    "\n",
    "- The output of these objects is data frames giving statistics at a category-level.\n",
    "- These are used as part of `TermScorers` which produce category-association scores for terms.\n",
    "- N.B.\n",
    "    - Currently, only three are implemented, and the ones which rely on document size use feature counts found in the term-document matrix. \n",
    "    - This means that if >1-grams are present or features have been removed, these will provide inaccurate estimates of document size. Use caution when using these, but they may still yield interesting results.\n",
    "- The first and simplest is called the `AbsoluteFrequencyRanker`, where the sum of the number of terms in each category is returned. The `label_append` is a string concatenated to each category's name. The `label_append` is useful if other category-specific metrics will be added to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Count</th>\n",
       "      <th>Positive Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>2287</td>\n",
       "      <td>2351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>949</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>2148</td>\n",
       "      <td>2466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative Count  Positive Count\n",
       "term                                    \n",
       "captures               1               5\n",
       "the                 2287            2351\n",
       "half                  27              14\n",
       "-                    949             902\n",
       ",                   2148            2466"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.AbsoluteFrequencyRanker(unigram_corpus).get_ranks(label_append=' Count').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OncePerDocFrequencyRanker` ignores terms that occur in more than one document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Documents</th>\n",
       "      <th>Positive Documents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1364</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>634</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>1366</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative Documents  Positive Documents\n",
       "term                                            \n",
       "captures                   1                   5\n",
       "the                     1364                1414\n",
       "half                      26                  13\n",
       "-                        634                 642\n",
       ",                       1366                1488"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.OncePerDocFrequencyRanker(unigram_corpus).get_ranks(label_append=' Documents').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DocLengthNormalizedFrequencyRanker` weights each term by its document percentage, i.e., \n",
    "\n",
    "$$\\mbox{weight}_{t,c} = \\sum_{\\mbox{doc } d \\ \\in \\mbox{category } c} \\frac{\\#(t, d)}{|d|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkessler/anaconda3/envs/py38/lib/python3.7/site-packages/scipy/sparse/base.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.true_divide(self.todense(), other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Percentages</th>\n",
       "      <th>Positive Percentages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.298333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>115.924483</td>\n",
       "      <td>117.177789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>1.340761</td>\n",
       "      <td>0.711467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>50.754314</td>\n",
       "      <td>45.370685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>108.902535</td>\n",
       "      <td>123.622976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative Percentages  Positive Percentages\n",
       "captures              0.041667              0.298333\n",
       "the                 115.924483            117.177789\n",
       "half                  1.340761              0.711467\n",
       "-                    50.754314             45.370685\n",
       ",                   108.902535            123.622976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.DocLengthNormalizedFrequencyRanker(unigram_corpus).get_ranks(label_append=' Percentages').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom TermRankers\n",
    "\n",
    "We can implement our own term ranker by creating a subclass of `scattertext.termranking.TermRanker.TermRanker` or `st.TermRanker`. \n",
    "\n",
    "This custom ranker will return mean tf.idf scores for each document in a category. Note that the term frequencies are square-root scaled.\n",
    "\n",
    "The `TermRanker.get_term_doc_mat()` returns a document-row/term-column CSR sparse matrix, with values indicating the number of times a term appeared in that document.\n",
    "\n",
    "A data frame should be returned indexed on terms and with the index named \"term\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTFIDF(st.TermRanker):\n",
    "    def get_ranks(self, label_append: str=' mean tf.idf') -> pd.DataFrame:\n",
    "        sqrt_tf = np.sqrt(self.get_term_doc_mat())\n",
    "        idf = np.log(self._corpus.get_num_docs()/(sqrt_tf>0).sum(axis=0).A1)\n",
    "        tfidf = sqrt_tf.multiply(idf).tocsr()\n",
    "        y = self._corpus.get_category_ids()        \n",
    "        return pd.DataFrame({\n",
    "            cat+label_append : tfidf[y == cat_i, :].mean(axis=0).A1\n",
    "            for cat_i, cat \n",
    "            in enumerate(self._corpus.get_categories())\n",
    "        }).assign(\n",
    "            term = self._corpus.get_terms()\n",
    "        ).set_index('term')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative mean tf.idf</th>\n",
       "      <th>Positive mean tf.idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.013642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.397556</td>\n",
       "      <td>0.403445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>0.052877</td>\n",
       "      <td>0.026372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.416547</td>\n",
       "      <td>0.403839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.368237</td>\n",
       "      <td>0.403435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative mean tf.idf  Positive mean tf.idf\n",
       "term                                                \n",
       "captures              0.002778              0.013642\n",
       "the                   0.397556              0.403445\n",
       "half                  0.052877              0.026372\n",
       "-                     0.416547              0.403839\n",
       ",                     0.368237              0.403435"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MeanTFIDF(unigram_corpus).get_ranks().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting language difference between positive and negative reviews\n",
    "\n",
    "- Scattertext projects unigrams on a scatterplot based on the rank of their frequencies in each category. \n",
    "- The placement and color of each term are given in the `plot_df` data frame, where `Xpos` and `Ypos` indicate term coordinates ($\\in [0,1]^2$).\n",
    "- Scattertext attempts to label as many points as possible on the plot.\n",
    "- The ColorScore indicates which terms receive bluer (more positive) or more red (more negative) point colors. \n",
    "  - The score is based on the difference between the scaled category frequency ranks.\n",
    "  - Terms receiving the highest and lowest scores are labeled \"Top Newer\" and \"Top Older.\"\n",
    "- The unusual terms in the corpus (as judged by a set of general-purpose term frequencies) are displayed in the Characteristic column. \n",
    "- The newer function `dataframe_scattertext` function renders the scatter plot.\n",
    "- Clicking on a term displays its usage in context.\n",
    "- The get_heading(corpus) function returns the metadata text for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heading(corpus: st.ParsedCorpus):\n",
    "    return corpus.get_df().movie_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 3, 3, 4])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.rankdata([0, 0, 1, 1, 2, 2, 3], 'dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scattertext/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_denserank_unigrams.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91a9cbb610>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df = st.AbsoluteFrequencyRanker(unigram_corpus).get_ranks(label_append='').assign(\n",
    "    X=lambda df: df.Positive,\n",
    "    Y=lambda df: df.Negative,\n",
    "    PosRank = lambda df: ss.rankdata(df.X, method='dense'),\n",
    "    NegRank = lambda df: ss.rankdata(df.Y, method='dense'),\n",
    "    Xpos=lambda df: st.scale(df.NegRank),\n",
    "    Ypos=lambda df: st.scale(df.PosRank),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero(df.Ypos - df.Xpos),\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': np.arange(0, 1, 0.01),\n",
    "    'y' :np.arange(0, 1, 0.01),\n",
    "})\n",
    "\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    unigram_corpus,\n",
    "    plot_df=plot_df,\n",
    "    category='Positive', \n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    width_in_pixels=1000, \n",
    "    ignore_categories=False,    \n",
    "    metadata=get_heading,\n",
    "    color_score_column='ColorScore',\n",
    "    left_list_column='ColorScore',\n",
    "    show_characteristic=False,\n",
    "    y_label='Positive Frequency Rank',\n",
    "    x_label='Negative Frequency Rank',\n",
    "    tooltip_columns=['PosRank', 'NegRank'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative'},\n",
    "    line_coordinates = line_df.to_dict('records'),   \n",
    ")\n",
    "\n",
    "fn = 'movie_denserank_unigrams.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the same action, but let's swap absolute frequencies for Mean TF.IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_mean_tf_idf_unigrams.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f951d69cf50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_heading(corpus: st.ParsedCorpus):\n",
    "    return corpus.get_df().movie_name\n",
    "\n",
    "plot_df = MeanTFIDF(unigram_corpus).get_ranks(label_append='').assign(\n",
    "    X=lambda df: df.Positive,\n",
    "    Y=lambda df: df.Negative,\n",
    "    PosRank = lambda df: ss.rankdata(df.X, method='dense'),\n",
    "    NegRank = lambda df: ss.rankdata(df.Y, method='dense'),\n",
    "    Xpos=lambda df: st.scale(df.NegRank),\n",
    "    Ypos=lambda df: st.scale(df.PosRank),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero(df.X - df.Y),\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': np.arange(0, 1, 0.01),\n",
    "    'y' :np.arange(0, 1, 0.01),\n",
    "})\n",
    "\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    unigram_corpus,\n",
    "    plot_df=plot_df,\n",
    "    category='Positive', \n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    width_in_pixels=1000, \n",
    "    ignore_categories=False,    \n",
    "    metadata=get_heading,\n",
    "    color_score_column='ColorScore',\n",
    "    left_list_column='ColorScore',\n",
    "    show_characteristic=False,\n",
    "    y_label='Positive Mean TF.IDF Rank',\n",
    "    x_label='Negative Mean TF.IDF Ranak',\n",
    "    tooltip_columns=['Positive', 'Negative'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative'},\n",
    "    line_coordinates = line_df.to_dict('records'),   \n",
    ")\n",
    "\n",
    "fn = 'movie_mean_tf_idf_unigrams.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>PosRank</th>\n",
       "      <th>NegRank</th>\n",
       "      <th>Xpos</th>\n",
       "      <th>Ypos</th>\n",
       "      <th>ColorScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>96</td>\n",
       "      <td>13</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.140118</td>\n",
       "      <td>0.551690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.397556</td>\n",
       "      <td>0.403445</td>\n",
       "      <td>0.403445</td>\n",
       "      <td>0.397556</td>\n",
       "      <td>675</td>\n",
       "      <td>709</td>\n",
       "      <td>0.997183</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>0.528024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>0.052877</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.052877</td>\n",
       "      <td>258</td>\n",
       "      <td>516</td>\n",
       "      <td>0.725352</td>\n",
       "      <td>0.379056</td>\n",
       "      <td>0.401040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.416547</td>\n",
       "      <td>0.403839</td>\n",
       "      <td>0.403839</td>\n",
       "      <td>0.416547</td>\n",
       "      <td>676</td>\n",
       "      <td>710</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>0.995575</td>\n",
       "      <td>0.452554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.368237</td>\n",
       "      <td>0.403435</td>\n",
       "      <td>0.403435</td>\n",
       "      <td>0.368237</td>\n",
       "      <td>674</td>\n",
       "      <td>704</td>\n",
       "      <td>0.990141</td>\n",
       "      <td>0.992625</td>\n",
       "      <td>0.667472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfaithful</th>\n",
       "      <td>0.014944</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>0.164789</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyne</th>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>0.094366</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>0.489321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallace</th>\n",
       "      <td>0.016741</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>40</td>\n",
       "      <td>147</td>\n",
       "      <td>0.205634</td>\n",
       "      <td>0.057522</td>\n",
       "      <td>0.466205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oleander</th>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>66</td>\n",
       "      <td>26</td>\n",
       "      <td>0.035211</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.525490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windtalkers</th>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>38</td>\n",
       "      <td>195</td>\n",
       "      <td>0.273239</td>\n",
       "      <td>0.054572</td>\n",
       "      <td>0.452322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Negative  Positive         X         Y  PosRank  NegRank  \\\n",
       "term                                                                    \n",
       "captures     0.002778  0.013642  0.013642  0.002778       96       13   \n",
       "the          0.397556  0.403445  0.403445  0.397556      675      709   \n",
       "half         0.052877  0.026372  0.026372  0.052877      258      516   \n",
       "-            0.416547  0.403839  0.403839  0.416547      676      710   \n",
       ",            0.368237  0.403435  0.403435  0.368237      674      704   \n",
       "...               ...       ...       ...       ...      ...      ...   \n",
       "unfaithful   0.014944  0.014676  0.014676  0.014944      112      118   \n",
       "lyne         0.010857  0.007997  0.007997  0.010857       42       68   \n",
       "wallace      0.016741  0.007690  0.007690  0.016741       40      147   \n",
       "oleander     0.005556  0.010914  0.010914  0.005556       66       26   \n",
       "windtalkers  0.020214  0.007445  0.007445  0.020214       38      195   \n",
       "\n",
       "                 Xpos      Ypos  ColorScore  \n",
       "term                                         \n",
       "captures     0.016901  0.140118    0.551690  \n",
       "the          0.997183  0.994100    0.528024  \n",
       "half         0.725352  0.379056    0.401040  \n",
       "-            0.998592  0.995575    0.452554  \n",
       ",            0.990141  0.992625    0.667472  \n",
       "...               ...       ...         ...  \n",
       "unfaithful   0.164789  0.163717    0.499000  \n",
       "lyne         0.094366  0.060472    0.489321  \n",
       "wallace      0.205634  0.057522    0.466205  \n",
       "oleander     0.035211  0.095870    0.525490  \n",
       "windtalkers  0.273239  0.054572    0.452322  \n",
       "\n",
       "[2083 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyness in Scattertext: Term Scorers\n",
    "\n",
    "- Given a corpus, we can produce scores and statistics for how associated features are to a particular category.\n",
    "- Subclasses of `CorpusBasedTermScorer` can produce these scores and use a `TermRanker` in the process.\n",
    "- We will look at some built-in term scorers and see how to write our own.\n",
    "- First, let's examine a simple term scorer, the smoothed log odds ratio, implemented in the `LogOddsRatioScorer` class.\n",
    "\n",
    "The log odds ratio, comparing a category $a$ against a category $b$, is defined as:\n",
    "\n",
    "$$ \\mbox{Log-Odds-Ratio}(\\mbox{term}_i, \\mbox{category}_a, \\mbox{category}_b) = \\log \\frac{\\#_{ai}}{|a| - \\#_{ai}} - \\log \\frac{\\#_{bi}}{|b| - \\#_{bi}} $$\n",
    "\n",
    "where $\\#_{\\mbox{category}, \\mbox{term index}}$ is the number of times a term occurred in a category, and $|\\mbox{category}|$ is the number of terms in a category.\n",
    "\n",
    "- Pseudo counts of a small $\\alpha$ (often 0.01) are added to each term count to prevent undefined values when a term does not appear in a category,\n",
    "\n",
    "- A single \"positive\" category and multiple \"negative\" categories are added to the TermScorer. By default, all categories which are not positive are considered as negative categories.\n",
    "\n",
    "We will first view the scores as a data frame, then plot them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative freq</th>\n",
       "      <th>Positive freq</th>\n",
       "      <th>Smoothed Log Odds Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boring</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.776894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seagal</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.651694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benigni</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.582684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinocchio</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.508559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stale</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.428501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>touching</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jones</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haynes</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>riveting</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winning</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.437568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Negative freq  Positive freq  Smoothed Log Odds Ratio\n",
       "term                                                            \n",
       "boring                17              0                -9.776894\n",
       "seagal                15              0                -9.651694\n",
       "benigni               14              0                -9.582684\n",
       "pinocchio             13              0                -9.508559\n",
       "stale                 12              0                -9.428501\n",
       "...                  ...            ...                      ...\n",
       "touching               0             12                 9.357511\n",
       "jones                  0             12                 9.357511\n",
       "haynes                 0             12                 9.357511\n",
       "riveting               0             12                 9.357511\n",
       "winning                0             13                 9.437568\n",
       "\n",
       "[2083 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.LogOddsRatioScorer(\n",
    "    unigram_corpus,\n",
    "    constant=0.001\n",
    ").set_term_ranker(\n",
    "    term_ranker=st.AbsoluteFrequencyRanker\n",
    ").set_categories(\n",
    "    category_name='Positive',\n",
    "    not_category_names=['Negative']\n",
    ").get_score_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score-centered visualization\n",
    "\n",
    "- Alternatively, we can visualize various keyness metrics against term frequency. \n",
    "- We can use `dataframe_scattertext`, or `produce_frequency_explorer`, which is both more conscise at the expense of being and less customizable.\n",
    "- Points are colored by the term scores, with bluer points with higher scores and redder points with lower scors.\n",
    "- It takes the corpus, names of the positive and negative categories, and the list of negative categories (the `not_categories` parameter).\n",
    "- It includes a `minimum_term_frequency` threshold (you should typically set this to zero) and a `grey threshold` parameter, which gives an absolute value of range of scores to gery out. This is useful when the score ia p-value or z-score and a significance threshold is used.\n",
    "- Examining the plot, we can see that terms closely related to films, such as actors and directors score highly. These are mostly associated with movies which had exclusively positive or negative. \"Segal\" for example, appeared in all reviews for Half Past Dead, a movie which was panned in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movies_log_odds_ratio_smoothed.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f951ab60c50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    not_categories=['Negative'],\n",
    "    term_scorer=st.LogOddsRatioScorer,\n",
    "    term_ranker=st.AbsoluteFrequencyRanker,\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_log_odds_ratio_smoothed.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Cohen's $d$\n",
    "\n",
    "Cohen's $d$ computes an effect size for each term. An effect size is the number of pooled standard deviations which separate the category means. It assumes a normal distribution of terms across documents. Given the bursty nature of term distributions (e.g., seeing a term once in a document will make it far likely to see it again than if it wasn't seen at all), this tends not to hold. \n",
    "\n",
    "We can see a data frame of the components used to compute Cohen's $d$ and Hedge's $r$, along with significances in the form of p- and z- scores.\n",
    "\n",
    "Corrections for multiple comparisons should be made before these are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkessler/anaconda3/envs/py38/lib/python3.7/site-packages/scipy/sparse/base.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.true_divide(self.todense(), other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohens_d</th>\n",
       "      <th>cohens_d_se</th>\n",
       "      <th>cohens_d_z</th>\n",
       "      <th>cohens_d_p</th>\n",
       "      <th>hedges_r</th>\n",
       "      <th>hedges_r_se</th>\n",
       "      <th>hedges_r_z</th>\n",
       "      <th>hedges_r_p</th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>count1</th>\n",
       "      <th>count2</th>\n",
       "      <th>docs1</th>\n",
       "      <th>docs2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.047990</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>1.673563</td>\n",
       "      <td>0.047108</td>\n",
       "      <td>0.047982</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>1.673340</td>\n",
       "      <td>0.047130</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.006458</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>-0.225228</td>\n",
       "      <td>0.589099</td>\n",
       "      <td>-0.006457</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>-0.225230</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.047730</td>\n",
       "      <td>0.048081</td>\n",
       "      <td>2351</td>\n",
       "      <td>2287</td>\n",
       "      <td>1414</td>\n",
       "      <td>1364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>-0.050074</td>\n",
       "      <td>0.028676</td>\n",
       "      <td>-1.746225</td>\n",
       "      <td>0.959614</td>\n",
       "      <td>-0.050066</td>\n",
       "      <td>0.028675</td>\n",
       "      <td>-1.745970</td>\n",
       "      <td>0.959592</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>-0.061755</td>\n",
       "      <td>0.028678</td>\n",
       "      <td>-2.153403</td>\n",
       "      <td>0.984356</td>\n",
       "      <td>-0.061746</td>\n",
       "      <td>0.028680</td>\n",
       "      <td>-2.152913</td>\n",
       "      <td>0.984337</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.021051</td>\n",
       "      <td>902</td>\n",
       "      <td>949</td>\n",
       "      <td>642</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.094021</td>\n",
       "      <td>0.028687</td>\n",
       "      <td>3.277480</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.094006</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>3.275707</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.050356</td>\n",
       "      <td>0.045169</td>\n",
       "      <td>2466</td>\n",
       "      <td>2148</td>\n",
       "      <td>1488</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfaithful</th>\n",
       "      <td>-0.011394</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>-0.397398</td>\n",
       "      <td>0.654463</td>\n",
       "      <td>-0.011392</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>-0.397399</td>\n",
       "      <td>0.654463</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyne</th>\n",
       "      <td>-0.012766</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>-0.445245</td>\n",
       "      <td>0.671929</td>\n",
       "      <td>-0.012764</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>-0.445245</td>\n",
       "      <td>0.671929</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallace</th>\n",
       "      <td>-0.030364</td>\n",
       "      <td>0.028673</td>\n",
       "      <td>-1.058975</td>\n",
       "      <td>0.855194</td>\n",
       "      <td>-0.030359</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>-1.058925</td>\n",
       "      <td>0.855183</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oleander</th>\n",
       "      <td>0.013130</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>0.457961</td>\n",
       "      <td>0.323490</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.028667</td>\n",
       "      <td>0.457961</td>\n",
       "      <td>0.323490</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windtalkers</th>\n",
       "      <td>-0.026574</td>\n",
       "      <td>0.028672</td>\n",
       "      <td>-0.926820</td>\n",
       "      <td>0.822990</td>\n",
       "      <td>-0.026570</td>\n",
       "      <td>0.028669</td>\n",
       "      <td>-0.926789</td>\n",
       "      <td>0.822982</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cohens_d  cohens_d_se  cohens_d_z  cohens_d_p  hedges_r  \\\n",
       "term                                                                   \n",
       "captures     0.047990     0.028675    1.673563    0.047108  0.047982   \n",
       "the         -0.006458     0.028671   -0.225228    0.589099 -0.006457   \n",
       "half        -0.050074     0.028676   -1.746225    0.959614 -0.050066   \n",
       "-           -0.061755     0.028678   -2.153403    0.984356 -0.061746   \n",
       ",            0.094021     0.028687    3.277480    0.000524  0.094006   \n",
       "...               ...          ...         ...         ...       ...   \n",
       "unfaithful  -0.011394     0.028671   -0.397398    0.654463 -0.011392   \n",
       "lyne        -0.012766     0.028671   -0.445245    0.671929 -0.012764   \n",
       "wallace     -0.030364     0.028673   -1.058975    0.855194 -0.030359   \n",
       "oleander     0.013130     0.028671    0.457961    0.323490  0.013128   \n",
       "windtalkers -0.026574     0.028672   -0.926820    0.822990 -0.026570   \n",
       "\n",
       "             hedges_r_se  hedges_r_z  hedges_r_p        m1        m2  count1  \\\n",
       "term                                                                           \n",
       "captures        0.028675    1.673340    0.047130  0.000122  0.000017       5   \n",
       "the             0.028667   -0.225230    0.589100  0.047730  0.048081    2351   \n",
       "half            0.028675   -1.745970    0.959592  0.000290  0.000556      14   \n",
       "-               0.028680   -2.152913    0.984337  0.018481  0.021051     902   \n",
       ",               0.028698    3.275707    0.000527  0.050356  0.045169    2466   \n",
       "...                  ...         ...         ...       ...       ...     ...   \n",
       "unfaithful      0.028667   -0.397399    0.654463  0.000125  0.000160       6   \n",
       "lyne            0.028667   -0.445245    0.671929  0.000069  0.000097       3   \n",
       "wallace         0.028670   -1.058925    0.855183  0.000071  0.000157       3   \n",
       "oleander        0.028667    0.457961    0.323490  0.000073  0.000049       4   \n",
       "windtalkers     0.028669   -0.926789    0.822982  0.000081  0.000152       3   \n",
       "\n",
       "             count2  docs1  docs2  \n",
       "term                               \n",
       "captures          1      5      1  \n",
       "the            2287   1414   1364  \n",
       "half             27     13     26  \n",
       "-               949    642    634  \n",
       ",              2148   1488   1366  \n",
       "...             ...    ...    ...  \n",
       "unfaithful        6      6      6  \n",
       "lyne              4      3      4  \n",
       "wallace           7      3      6  \n",
       "oleander          2      4      2  \n",
       "windtalkers       8      3      8  \n",
       "\n",
       "[2083 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.CohensD(unigram_corpus).set_categories('Positive').get_score_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect sizes can be plotted like with other term scorers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkessler/anaconda3/envs/py38/lib/python3.7/site-packages/scipy/sparse/base.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.true_divide(self.todense(), other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movies_cohensd.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f951c2414d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Negative',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.CohensD,\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_cohensd.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyness metrics from Monroe (2008): Log odds ratio with uninformative and informative priors\n",
    "\n",
    "These are variance-adjusted versions of the log odds ratio. One involves an uninformative prior, equivalent to a pseudo-count in the log odds ratio. The other involves using word frequencies from a neutral corpus as prior counts. These prior counts are added to both scores.\n",
    "\n",
    "On first inspection, the term scores are no longer over(?)-sensitive to terms that do not appear in the other category. Frequent terms which appear more in one category than the other are possibly overweighted. For example, \"and,\" which appears about 2600 times in the corpus, and is 34% more likely to occur in positive than negative reviews, is the most highly weighted term.\n",
    "\n",
    "Note taht we use the `term_scorer_kwargs` to pass a keyword arguments to the term scorer constructor. These are in addition to the first argument which is the corpus.\n",
    "\n",
    "Burt L. Monroe, Michael P. Colaresi, and Kevin M. Quinn. Fightin' words: Lexical feature selection and evaluation for identifying the content of political conflict. Political Analysis. 2008.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movies_log_odds_ratio_uninformative_prior.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f951c6a0fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Negative',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.LogOddsRatioUninformativePriorScorer,\n",
    "    term_scorer_kwargs={'alpha': 0.001},\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_log_odds_ratio_uninformative_prior.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Odds Ratio with Informative Prior\n",
    "\n",
    "We use `unigram_corpus_full`, which also includes the \"Plot\" category. These are descriptions of movie plots and should not carry sentiment. We add counts from these plots to both categories, creating what Monroe et al. refer to as a Dirichlet prior.\n",
    "\n",
    "We start by using the `PriorFactory`, specifying the positive and negative categories to get counts from neutral categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a              665.001\n",
       "at              61.001\n",
       "an             133.001\n",
       "college          4.001\n",
       "(              162.001\n",
       "                ...   \n",
       "tadpole          0.001\n",
       "unfaithful       0.001\n",
       "lyne             0.001\n",
       "wallace          0.001\n",
       "windtalkers      0.001\n",
       "Length: 2376, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priors = st.PriorFactory(\n",
    "    unigram_corpus_full, \n",
    "    category='Positive', \n",
    "    not_categories=['Negative'],\n",
    "    starting_count=0.001,\n",
    "    term_ranker=st.AbsoluteFrequencyRanker\n",
    ").use_neutral_categories(\n",
    ").get_priors()\n",
    "priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use `LogOddsRatioUniformativePriorScorer`,  multiplying the prior counts by 6, a little more than the total word count of the positive/negative categories.\n",
    "\n",
    "This brings back the emphasis on rarer words. \n",
    "\n",
    "It's a clever idea and can be used in a lot of places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plot freq        1.000000\n",
       "Negative freq    2.725077\n",
       "Positive freq    2.826909\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda s: s/s['Plot freq'])(st.AbsoluteFrequencyRanker(unigram_corpus_full).get_ranks().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movies_log_odds_ratio_informative_prior.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f951c241b10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus_full,\n",
    "    category='Positive',\n",
    "    category_name='Negative',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.LogOddsRatioInformativePriorScorer,\n",
    "    term_scorer_kwargs={'prior_scale': 6, 'prior_counts': priors},\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_log_odds_ratio_informative_prior.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available term scorers:\n",
    "\n",
    "- `st.BetaPosterior` Beta Posterior (Bamman et al 2014) as reported by (Chang and McKeown, 2019).\n",
    "- `st.RelativeEntropy` Relative Entropy (Fankhauser et al 2014)\n",
    "- `st.BNSScorer` Bi-normal separation (Forman 2008)\n",
    "- `st.CohensD` Cohen's d; Hedges r, p-values and z-scores available in `CohensD.get_score_df`\n",
    "- `st.HedgesR` Hedge's r\n",
    "- `st.LogOddsRatio` Log odds ratio\n",
    "- `st.DeltaJSDivergenceScrorer` JS Divergence\n",
    "- `st.CraigsZetaScorer` Single category Craig's Zeta\n",
    "- `st.RankDifferenceScorer` Dense rank difference\n",
    "- `st.LogLikelihoodRatio` Log likelihood ratio (inspired by https://github.com/Zeta-and-Company/pydistinto/blob/main/scripts/measures/LLR.py)\n",
    "- `st.MannWhitneyU` Note: this is quite slow\n",
    "- `st.CredTFIDF` Credibility-adjusted TFIDF. From Kim and Zhang (2014)\n",
    "- `st.ScikitTermScorer` Wrapper for scikit-learn scorers.\n",
    "- and more\n",
    "\n",
    "\n",
    "David Bamman, Jacob Eisenstein, and Tyler Schnoebelen.  GENDER IDENTITY AND LEXICAL VARIATION IN SOCIAL MEDIA. 2014.\n",
    "\n",
    "Serina Chang and Kathleen McKeown. Automatically Inferring Gender Associations from Language. EMNLP 2019\n",
    "\n",
    "Peter Fankhauser, Jorg Knappen, Elke Teich. Exploring and visualizing variation in language resources. LREC 2014.\n",
    "    \n",
    "George Forman. BNS feature scaling: an improved representation over tf-idf for svm text classification. CIKM 2008.\n",
    "\n",
    "Yoon Kim and Owen Zhang. Implementation of Credibility Adjusted Term Frequency: A Supervised Term Weighting Scheme for Sentiment \n",
    "Analysis and Text Classification. WASSA 2014.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring word embeddings\n",
    "\n",
    "We can use scatterplots to visualize projections of fixed word embeddings, as well as to see how the usage of similar words differs across categories.\n",
    "\n",
    "We use Gensim's skipgram word embedder to produce 100d embeddings. Looking at the dendrogram of the most frequent 50 words, the emeddings appear to be reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist_corpus = unigram_corpus.get_stoplisted_corpus().filter_out(lambda x: re.match('^[A-Za-z]+$', x) is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = st.Word2VecFromParsedCorpus(stoplist_corpus).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 terms\n",
      "['movie', 'film', 'like', 'story', 'just', 'good', 'time', 'comedy', 'funny', 'best', 'way', 'director', 'little', 'action', 'characters', 'make', 'movies', 'bad', 'work', 'makes', 'life', 'big', 'really', 'fun', 'plot', 'old', 'thriller', 'new', 'year', 'films', 'better', 'character', 'love', 'great', 'script', 'drama', 'audience', 'long', 'cast', 'look', 'picture', 'hollywood', 'humor', 'minutes', 'performance', 'right', 'entertaining', 'real', 'man', 'people']\n",
      "Embedding of \"plot\"\n",
      "[ 0.2176692   0.15245606  0.07933028 -0.03732712  0.03754231 -0.09117519\n",
      "  0.15341374 -0.00681387  0.48257324  0.08225858 -0.0629556   0.02484483\n",
      "  0.12423413 -0.2011686   0.107204   -0.11764266  0.07956518  0.02487464\n",
      " -0.02958257  0.0117902  -0.04084276  0.11893637  0.04339759  0.00826036\n",
      "  0.19077031  0.07419693 -0.2297655   0.11265624 -0.11946397 -0.13932763\n",
      "  0.29778287  0.26348078  0.01898948 -0.19281906 -0.11353938  0.03929313\n",
      "  0.07703756 -0.30039355 -0.2925325  -0.06273728 -0.20518036 -0.1961461\n",
      "  0.09815588  0.12053332  0.27182057  0.27000043  0.01759211 -0.11497463\n",
      " -0.01531243  0.18902293  0.06809309  0.00790725  0.01857314  0.1667614\n",
      " -0.17606129 -0.03366564  0.05753795 -0.099691   -0.07889842  0.11656061\n",
      " -0.08882763 -0.01793888  0.04962024  0.02110683  0.20036924  0.1041429\n",
      "  0.14627549 -0.02619251  0.06759699 -0.13524494  0.01358863  0.11176821\n",
      " -0.04917642 -0.08114374  0.2759431   0.14611447  0.01817182  0.17080168\n",
      " -0.15477598 -0.30585146 -0.08866091  0.12205128  0.02807155  0.1219369\n",
      " -0.13440558  0.3755381   0.23848575 -0.1336661   0.09676873 -0.1591107\n",
      " -0.07926142  0.18657862  0.01606122  0.1875287   0.5443558   0.17998786\n",
      "  0.13662791 -0.02677403 -0.20465103 -0.0338113 ]\n",
      "Cosine distance of \"plot\" to \"script\" 0.5920671820640564\n",
      "Cosine distance of \"plot\" to \"year\" 1.0767926797270775\n",
      "Dimension of pairwise cosine distance of matrix: (50, 50)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_terms = list(stoplist_corpus.get_term_freq_df().sum(axis=1).sort_values(ascending=False).iloc[:50].index)\n",
    "print('Top 50 terms')\n",
    "print(top_terms)\n",
    "mat = np.array([model.wv[t] for t in top_terms])\n",
    "print('Embedding of \"plot\"')\n",
    "print(model.wv['plot'])\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return 1-np.dot(model.wv[a],model.wv[b])/(np.linalg.norm(model.wv[a])*np.linalg.norm(model.wv[b]))\n",
    "\n",
    "print('Cosine distance of \"plot\" to \"script\"', cosine_sim('plot', 'script'))\n",
    "print('Cosine distance of \"plot\" to \"year\"', cosine_sim('plot', 'year'))\n",
    "\n",
    "#print('Dimensions of term/embedding matrix:', mat.shape)\n",
    "\n",
    "\n",
    "sim_mat = cosine_distances(mat)\n",
    "print('Dimension of pairwise cosine distance of matrix:', sim_mat.shape)\n",
    "plt.figure(figsize=(8,14))\n",
    "dists = squareform(sim_mat)\n",
    "linkage_matrix = linkage(dists, \"single\")\n",
    "dendrogram(linkage_matrix, labels=top_terms, orientation='right', leaf_font_size=12.,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP Visualization of Emeddings\n",
    "To get a sense of the embedding space, we can use UMAP to project the embedding space into two dimensions, where words whose embeddings have a small cosine distance are plotted close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scattertext/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_umap.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f94f8d74b90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = np.array([model.wv[w] for w in stoplist_corpus.get_terms()]).T\n",
    "projection_raw = umap.UMAP(min_dist=0.5, metric='cosine').fit_transform(embeddings.T)\n",
    "\n",
    "plot_df = pd.DataFrame({\n",
    "    'term': stoplist_corpus.get_terms(),\n",
    "    'X': projection_raw.T[0],\n",
    "    'Y': projection_raw.T[1],\n",
    "}).set_index('term').assign(\n",
    "    XPos=lambda df: st.scale(df.X),\n",
    "    YPos=lambda df: st.scale(df.Y),\n",
    "    Color = '#6888BE'\n",
    ")\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    stoplist_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    plot_df=plot_df,\n",
    "    metadata=get_heading,\n",
    "    ignore_categories=False,\n",
    "    use_full_doc=True,\n",
    "    x_label='UMAP 0',\n",
    "    y_label='UMAP 1',\n",
    "    y_axis_labels=['More Negative', 'Neutral', 'More Positive'],\n",
    "    color_column='Color',\n",
    "    show_top_terms=False,\n",
    "    show_characteristic=False\n",
    ")\n",
    "fn = 'movie_umap.html'\n",
    "open(fn, 'wb').write(('<h2>UMAP Projection of Skip-gram Embeddings</h2>' + html).encode('utf-8'))\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus on identifying words similar to \"plot\" to see how a movie's plot is described in a positive or negative context.\n",
    "\n",
    "We first use Latent Semantic Scaling (Wantanabe, 2021) from the Gensim model we trained to compute the cosine similarity of the seed terms (in this case, only \"plot\") of all the terms in the positive seeds word list and 1 - the cosine similarity of the terms in the negative seed list. The average value cosine similarity of the positive and negative word lists is computed.\n",
    "\n",
    "Terms are colored based on their similarity to the word \"plot\".\n",
    "\n",
    "Kohei Watanabe. Latent Semantic Scaling: A Semisupervised Text Analysis Technique for New Domains and Languages. Communication Methods and Measures. 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>plot</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twists</th>\n",
       "      <td>0.512096</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stupidity</th>\n",
       "      <td>0.505377</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holes</th>\n",
       "      <td>0.502842</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clearly</th>\n",
       "      <td>0.490186</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screenplay</th>\n",
       "      <td>0.487577</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <td>0.482476</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parts</th>\n",
       "      <td>0.473262</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprises</th>\n",
       "      <td>0.455814</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premise</th>\n",
       "      <td>0.438908</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Similarity  Frequency\n",
       "plot          1.000000       99.0\n",
       "twists        0.512096       14.0\n",
       "stupidity     0.505377        6.0\n",
       "holes         0.502842       12.0\n",
       "clearly       0.490186        9.0\n",
       "screenplay    0.487577       30.0\n",
       "details       0.482476        7.0\n",
       "parts         0.473262        7.0\n",
       "surprises     0.455814       10.0\n",
       "premise       0.438908       26.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_df = pd.DataFrame({\n",
    "    'Similarity': st.latent_semantic_scale_from_word2vec(\n",
    "        model, \n",
    "        pos_seed_words=['plot']\n",
    "    ),\n",
    "    'Frequency': stoplist_corpus.get_term_freq_df().sum(axis=1),\n",
    "}).dropna().sort_values(by='Similarity', ascending=False)\n",
    "similar_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_plot_sim.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f950c4018d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_similar = similar_df.iloc[:100]\n",
    "similar_corpus = stoplist_corpus.whitelist_terms(top_similar.index)\n",
    "\n",
    "term_scorer = st.DeltaJSDivergenceScorer(similar_corpus).set_categories(category_name='Positive', not_category_names=['Negative'])\n",
    "\n",
    "plot_df = top_similar.assign(\n",
    "    SimilarScaled = lambda df: st.Scalers.scale(df.Similarity),\n",
    "    Association = term_scorer.get_scores(),\n",
    "    X = lambda df: df.Frequency,\n",
    "    Xpos = lambda df: st.Scalers.dense_rank(df.X),\n",
    "    Y = lambda df: df.Association,\n",
    "    Ypos = lambda df: st.Scalers.scale_center_zero_abs(df.Y)\n",
    ")\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    similar_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    plot_df=plot_df,\n",
    "    metadata=get_heading,\n",
    "    ignore_categories=False,\n",
    "    use_full_doc=True,\n",
    "    x_label='Frequency',\n",
    "    y_label=term_scorer.get_name(),\n",
    "    y_axis_labels=['More Negative', 'Neutral', 'More Positive'],\n",
    "    color_score_column='Similarity',\n",
    "    tooltip_columns=['Frequency', 'Association'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative', 'right': 'Similarity'},\n",
    "    left_list_column='Association',\n",
    "    right_order_column='Similarity',    \n",
    "    d3_color_scale='d3.interpolateCool'\n",
    "\n",
    ")\n",
    "fn = 'movie_plot_sim.html'\n",
    "with open(fn, 'wb') as of:\n",
    "    of.write(('<h2>Association to the word \"Plot\"</h2>' + html).encode('utf-8'))\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making use of pre-built lexicons\n",
    "\n",
    "Empath (Fast et al., 2016) provides 100 (fix this) pre-built topics. It is integrated to scattertext through the feature extraction class `FeatsFromOnlyEmpath`. \n",
    "\n",
    "Note that we used `FlexibleNGrams` to construct the previous corpora we worked with. The features outputted are through `FeatsFromOnlyEmpath` considered non-text features (called \"metadata\" in some places in Scattertext; not to be confused with document headings in the visualization which are *also* called metadata).\n",
    "\n",
    "Feature-extraction classes output text features through `get_feats` and non-text features through `get_doc_metadata`. This may change as Scattertext matures.\n",
    "\n",
    "Fast, Ethan, Binbin Chen, and Michael S. Bernstein. \"Empath: Understanding topic signals in large-scale text.\" Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'reading': 3, 'negative_emotion': 1, 'writing': 2})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.FeatsFromOnlyEmpath().get_doc_metadata(nlp('This is a scary story told by an author whose book was rejected by publishers 35 times.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 1, 'is': 1, 'a': 1, 'scary': 1, '...': 2, 'story': 1}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.FlexibleNGrams(ngram_sizes=[1,]).get_feats(nlp('This is a scary... story...'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cede4ece513c4be1ac83687c049fd2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4866 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_empath.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f94f9dc3f90>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_builder = st.FeatsFromOnlyEmpath()\n",
    "empath_corpus = st.CorpusFromParsedDocuments(\n",
    "    movie_df,\n",
    "    category_col='category',\n",
    "    parsed_col='SpacyParse',\n",
    "    feats_from_spacy_doc=feat_builder\n",
    ").build(show_progress=True)\n",
    "\n",
    "plot_df = st.AbsoluteFrequencyRanker(\n",
    "    empath_corpus\n",
    ").set_non_text(\n",
    "    non_text=True # Make sure you set this or you'll get a blank chart\n",
    ").get_ranks(\n",
    "    label_append=''\n",
    ").assign(\n",
    "    X=lambda df: df.Positive,\n",
    "    Y=lambda df: df.Negative,\n",
    "    PosRank = lambda df: ss.rankdata(df.X, method='dense'),\n",
    "    NegRank = lambda df: ss.rankdata(df.Y, method='dense'),\n",
    "    Xpos=lambda df: st.scale(df.NegRank),\n",
    "    Ypos=lambda df: st.scale(df.PosRank),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero(df.Ypos - df.Xpos),\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': np.arange(0, 1, 0.01),\n",
    "    'y' :np.arange(0, 1, 0.01),\n",
    "})\n",
    "\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    empath_corpus,\n",
    "    plot_df=plot_df,\n",
    "    category='Positive', \n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    width_in_pixels=1000, \n",
    "    ignore_categories=False,    \n",
    "    metadata=get_heading,\n",
    "    color_score_column='ColorScore',\n",
    "    left_list_column='ColorScore',\n",
    "    show_characteristic=False,\n",
    "    y_label='Positive Frequency Rank',\n",
    "    x_label='Negative Frequency Rank',\n",
    "    tooltip_columns=['PosRank', 'NegRank'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative'},\n",
    "    line_coordinates = line_df.to_dict('records'),   \n",
    "    use_non_text_features=True,\n",
    "    use_full_doc=True,\n",
    "    topic_model_term_lists=feat_builder.get_top_model_term_lists()\n",
    ")\n",
    "\n",
    "fn = 'movie_empath.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also add in features from a custom lexicon\n",
    "\n",
    "We create a data frame with topics that are columns, rows terms, and values real term-topic association.\n",
    "\n",
    "Let's cluster sentences extracted from the corpus using NMF over tf.idf represendations. This is just an example, and feel free to use the clustering method of your choice.\n",
    "\n",
    "We name topics by the conjunction of the two top terms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkessler/anaconda3/envs/py38/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:294: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie,action</th>\n",
       "      <th>film,family</th>\n",
       "      <th>like,feels</th>\n",
       "      <th>good,time</th>\n",
       "      <th>just,plain</th>\n",
       "      <th>comedy,romantic</th>\n",
       "      <th>story,characters</th>\n",
       "      <th>bad,really</th>\n",
       "      <th>best,year</th>\n",
       "      <th>funny,really</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>0.023589</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.050027</td>\n",
       "      <td>0.026907</td>\n",
       "      <td>0.027312</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creepy</th>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025371</td>\n",
       "      <td>0.001410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>college</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016459</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makes</th>\n",
       "      <td>0.048226</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>0.096980</td>\n",
       "      <td>0.025831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.134870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054038</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie,action  film,family  like,feels  good,time  just,plain  \\\n",
       "captures      0.000000     0.000000    0.000014   0.000000    0.000240   \n",
       "half          0.023589     0.016095    0.003933   0.008458    0.012405   \n",
       "creepy        0.006064     0.000000    0.015543   0.000000    0.000000   \n",
       "college       0.000000     0.000676    0.004961   0.001961    0.000090   \n",
       "makes         0.048226     0.014311    0.096980   0.025831    0.000000   \n",
       "\n",
       "          comedy,romantic  story,characters  bad,really  best,year  \\\n",
       "captures         0.001525          0.003193    0.000000   0.004988   \n",
       "half             0.050027          0.026907    0.027312   0.005605   \n",
       "creepy           0.002148          0.006900    0.000000   0.025371   \n",
       "college          0.010486          0.015700    0.000000   0.016459   \n",
       "makes            0.051500          0.134870    0.000000   0.054038   \n",
       "\n",
       "          funny,really  \n",
       "captures      0.000963  \n",
       "half          0.000000  \n",
       "creepy        0.001410  \n",
       "college       0.000000  \n",
       "makes         0.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "weight_df = st.SentencesForTopicModeling(\n",
    "    stoplist_corpus\n",
    ").get_topic_weights_df(\n",
    "    Pipeline([\n",
    "        ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "        ('nmf', (NMF(n_components=10, l1_ratio=.5, random_state=0)))\n",
    "    ])\n",
    ")\n",
    "    \n",
    "weight_df.columns = [','.join(weight_df[c].sort_values(ascending=False).index[:2]) for c in weight_df]\n",
    "weight_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4d915ec12c41e1af90315dc6b903d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4866 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scattertext/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_custom_topics.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f952ca67b90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_builder = st.FeatsFromScoredLexicon(lexicon_df = weight_df)\n",
    "custom_topic_corpus = st.CorpusFromParsedDocuments(\n",
    "    movie_df,\n",
    "    category_col='category',\n",
    "    parsed_col='SpacyParse',\n",
    "    feats_from_spacy_doc=feat_builder\n",
    ").build(show_progress=True)\n",
    "\n",
    "plot_df = st.AbsoluteFrequencyRanker(\n",
    "    custom_topic_corpus\n",
    ").set_non_text(\n",
    "    non_text=True # Make sure you set this or you'll get a blank chart\n",
    ").get_ranks(\n",
    "    label_append=''\n",
    ").assign(\n",
    "    X=lambda df: df.Positive,\n",
    "    Y=lambda df: df.Negative,\n",
    "    PosRank = lambda df: ss.rankdata(df.X, method='dense'),\n",
    "    NegRank = lambda df: ss.rankdata(df.Y, method='dense'),\n",
    "    Xpos=lambda df: st.scale(df.NegRank),\n",
    "    Ypos=lambda df: st.scale(df.PosRank),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero(df.Ypos - df.Xpos),\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': np.arange(0, 1, 0.01),\n",
    "    'y' :np.arange(0, 1, 0.01),\n",
    "})\n",
    "\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    custom_topic_corpus,\n",
    "    plot_df=plot_df,\n",
    "    category='Positive', \n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    width_in_pixels=1000, \n",
    "    ignore_categories=False,    \n",
    "    metadata=get_heading,\n",
    "    color_score_column='ColorScore',\n",
    "    left_list_column='ColorScore',\n",
    "    show_characteristic=False,\n",
    "    y_label='Positive Frequency Rank',\n",
    "    x_label='Negative Frequency Rank',\n",
    "    tooltip_columns=['PosRank', 'NegRank'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative'},\n",
    "    line_coordinates = line_df.to_dict('records'),   \n",
    "    use_non_text_features=True,\n",
    "    use_full_doc=True,\n",
    "    topic_model_term_lists=feat_builder.get_top_model_term_lists()\n",
    ")\n",
    "\n",
    "fn = 'movie_custom_topics.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispersion\n",
    "\n",
    "Let's examine dispersion at the movie grain. We first will change the category definitions from review polarity to the movie name through the recategorize function. \n",
    "\n",
    "Scattertext also has the capability of analyzing dispersion at the document grain, but since reviews in this corpus are short and unlikely to contain the same term twice it would--outside of analyzing the interactions between terms presence and document length--be unfruitful to analyze them through dispersion.\n",
    "\n",
    "Instead, we analyze at the category grain by passing the `use_categories=True`.\n",
    "\n",
    "We can examine document-level dispersion through the `Dispersion` class, which computes a data frame with the dispersion metrics from Gries (2019) via `get_df`.\n",
    "\n",
    "We can optionally include Burch's DA in the data frame using `get_df(include_da=True)`. Since DA requires $O(|\\ \\mbox{segments}\\ |^2)$ comparisons, I tend to limit this to when there are under 200 segments.\n",
    "\n",
    "Stefan Th. Gries. Analyzing dispersion. Practical handbook of corpus linguistics. Springer. 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New category (movie) count: 156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Range</th>\n",
       "      <th>SD</th>\n",
       "      <th>VC</th>\n",
       "      <th>Juilland's D</th>\n",
       "      <th>Rosengren's S</th>\n",
       "      <th>DP</th>\n",
       "      <th>DP norm</th>\n",
       "      <th>KL-divergence</th>\n",
       "      <th>DA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.969505e-01</td>\n",
       "      <td>0.041619</td>\n",
       "      <td>0.958306</td>\n",
       "      <td>0.959034</td>\n",
       "      <td>4.589219</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>4638</td>\n",
       "      <td>155</td>\n",
       "      <td>11.617486</td>\n",
       "      <td>0.390756</td>\n",
       "      <td>9.792950e-01</td>\n",
       "      <td>0.987393</td>\n",
       "      <td>0.082845</td>\n",
       "      <td>0.082908</td>\n",
       "      <td>0.034386</td>\n",
       "      <td>0.787495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>0.621332</td>\n",
       "      <td>2.364093</td>\n",
       "      <td>8.121275e-01</td>\n",
       "      <td>0.203935</td>\n",
       "      <td>0.785484</td>\n",
       "      <td>0.786081</td>\n",
       "      <td>2.374957</td>\n",
       "      <td>0.146027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>1851</td>\n",
       "      <td>152</td>\n",
       "      <td>6.042676</td>\n",
       "      <td>0.509269</td>\n",
       "      <td>9.625530e-01</td>\n",
       "      <td>0.950057</td>\n",
       "      <td>0.160362</td>\n",
       "      <td>0.160483</td>\n",
       "      <td>0.128116</td>\n",
       "      <td>0.712529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>4614</td>\n",
       "      <td>156</td>\n",
       "      <td>11.246104</td>\n",
       "      <td>0.380232</td>\n",
       "      <td>9.834928e-01</td>\n",
       "      <td>0.990712</td>\n",
       "      <td>0.075676</td>\n",
       "      <td>0.075733</td>\n",
       "      <td>0.026630</td>\n",
       "      <td>0.791280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfaithful</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957685</td>\n",
       "      <td>12.449900</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.992957</td>\n",
       "      <td>0.993712</td>\n",
       "      <td>7.149575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyne</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558649</td>\n",
       "      <td>12.449900</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.992957</td>\n",
       "      <td>0.993712</td>\n",
       "      <td>7.149575</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallace</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798070</td>\n",
       "      <td>12.449900</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.992197</td>\n",
       "      <td>0.992952</td>\n",
       "      <td>7.001802</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oleander</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478842</td>\n",
       "      <td>12.449900</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>0.992718</td>\n",
       "      <td>0.993473</td>\n",
       "      <td>7.101481</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windtalkers</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.877878</td>\n",
       "      <td>12.449900</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.992067</td>\n",
       "      <td>0.992821</td>\n",
       "      <td>6.977922</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Frequency  Range         SD         VC  Juilland's D  \\\n",
       "captures             6      6   0.192308   5.000000  5.969505e-01   \n",
       "the               4638    155  11.617486   0.390756  9.792950e-01   \n",
       "half                41     30   0.621332   2.364093  8.121275e-01   \n",
       "-                 1851    152   6.042676   0.509269  9.625530e-01   \n",
       ",                 4614    156  11.246104   0.380232  9.834928e-01   \n",
       "...                ...    ...        ...        ...           ...   \n",
       "unfaithful          12      1   0.957685  12.449900  0.000000e+00   \n",
       "lyne                 7      1   0.558649  12.449900  0.000000e+00   \n",
       "wallace             10      1   0.798070  12.449900  0.000000e+00   \n",
       "oleander             6      1   0.478842  12.449900 -2.220446e-16   \n",
       "windtalkers         11      1   0.877878  12.449900  1.110223e-16   \n",
       "\n",
       "             Rosengren's S        DP   DP norm  KL-divergence        DA  \n",
       "captures          0.041619  0.958306  0.959034       4.589219  0.032258  \n",
       "the               0.987393  0.082845  0.082908       0.034386  0.787495  \n",
       "half              0.203935  0.785484  0.786081       2.374957  0.146027  \n",
       "-                 0.950057  0.160362  0.160483       0.128116  0.712529  \n",
       ",                 0.990712  0.075676  0.075733       0.026630  0.791280  \n",
       "...                    ...       ...       ...            ...       ...  \n",
       "unfaithful        0.007043  0.992957  0.993712       7.149575  0.000000  \n",
       "lyne              0.007043  0.992957  0.993712       7.149575  0.000000  \n",
       "wallace           0.007803  0.992197  0.992952       7.001802  0.000000  \n",
       "oleander          0.007282  0.992718  0.993473       7.101481  0.000000  \n",
       "windtalkers       0.007933  0.992067  0.992821       6.977922  0.000000  \n",
       "\n",
       "[2083 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_corpus = unigram_corpus.recategorize(unigram_corpus.get_df()['movie_name'])\n",
    "print(\"New category (movie) count:\", movie_corpus.get_num_categories())\n",
    "\n",
    "dispersion_df = st.Dispersion(movie_corpus, use_categories=True).get_df(include_da = True)\n",
    "dispersion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize dispersion by graphing a value against the frequency. Let's use Greis' DP as an example.\n",
    "\n",
    "A term's DP refers to the sum, for each part, to the difference in the percentage of its mentions in that part relative to the percentage of the corpus that part occupies. \n",
    "\n",
    "We will scale the DP from its minimum to its maximum on the y-axis and the dense rank of the frequency on the x-axis.\n",
    "\n",
    "We see that DP has a strong inverse correlation to the frequency rank. If we account for that correlation, we see genre words (e.g., \"comedy,\" \"action,\" \"funny,\" etc.) stand out as having a higher-than-expected DP.\n",
    "\n",
    "We use mean bootstraps of isotonic regression, a non-parametric method which fits a sequence of monotonically increasing horizontal line segments to the data. If the relationship between frequency and the metric is seen to be negative, it will fit a monotonicly decreasing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_dispersion_convenience(metric, dispersion_df, corpus, smoother, plot_residual=False):\n",
    "    expected = smoother.fit(\n",
    "        np.array([dispersion_df.Frequency.values]).T,\n",
    "        dispersion_df[metric].values\n",
    "    ).predict(np.array([dispersion_df.Frequency.values]).T).T[0]\n",
    "    \n",
    "    if plot_residual:\n",
    "        y = expected - dispersion_df[metric].values\n",
    "        y_pos = st.Scalers.scale_center_zero_abs(y)\n",
    "        \n",
    "    else:\n",
    "        all_scale = st.scale(np.concatenate([dispersion_df[metric].values, expected]))\n",
    "        y = dispersion_df[metric]\n",
    "        y_pos = all_scale[:len(dispersion_df)]\n",
    "        line_y = all_scale[len(dispersion_df):]\n",
    "\n",
    "    plot_df=dispersion_df.assign(\n",
    "        X=lambda df: df.Frequency,\n",
    "        Xpos=lambda df: st.Scalers.dense_rank(df.X),\n",
    "        Y=lambda df: y,\n",
    "        Ypos=lambda df: y_pos,\n",
    "        Expected=expected,\n",
    "        Residual=lambda df: y if plot_residual else df.Ypos - st.scale(df.Y, df.Expected),\n",
    "        Color='#ffbf00'\n",
    "    )\n",
    "\n",
    "    line_df = pd.DataFrame({\n",
    "        'x': plot_df.Xpos.values,\n",
    "        'y': line_y if plot_residual is False else 0.5,\n",
    "    }).sort_values(by='x')\n",
    "\n",
    "    return st.dataframe_scattertext(\n",
    "        corpus,\n",
    "        plot_df=plot_df,\n",
    "        metadata=get_heading,\n",
    "        ignore_categories=False,\n",
    "        x_label='Log Frequency',\n",
    "        y_label=metric + ' Resdiual' if plot_residual else '',\n",
    "        y_axis_labels=['Low', 'Medium', 'High'],\n",
    "        color_column='Color',\n",
    "        tooltip_columns=['Frequency', metric],\n",
    "        header_names={'upper': f'Top {metric}', 'lower': f'Bottom {metric}'},\n",
    "        left_list_column=metric if plot_residual is False else \"Y\",\n",
    "        show_characteristic=False,\n",
    "        line_coordinates = line_df.to_dict('records')\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scattertext/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_dispersion_DP.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91a9ec5e50>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=plot_dispersion_convenience('DP', dispersion_df, movie_corpus, smoother=st.smoothing.mean_isotonic.MeanIsotonic())\n",
    "fn = f'movie_dispersion_DP.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KL-Divergence, namely $KLD(P(term|segment)\\ ||\\ P(segment))$, has a particularly high variance for infrequent terms. This variance is due to the differences in document size the trms occur in. However, the Low "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_dispersion_KLD.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91adf8e9d0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=plot_dispersion_convenience('KL-divergence', dispersion_df, movie_corpus, st.smoothing.lowess.Lowess())\n",
    "fn = f'movie_dispersion_KLD.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DA (Burch et al., 2017) uses the mean difference between all part pairs, with DA at 0, contrary to DP, indicating perfect dispersion, while 1 indicates complete concentration in one category. 0.5 corresponds to the mean absolute difference in frequencies equaling the mean frequency. \n",
    "\n",
    "Burch, B., Egbert, J., and Biber, D. Measuring and interpreting lexical dispersion in corpus linguistics. Journal of Research Design and Statistics in\n",
    "Linguistics and Communication Science. 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scattertext/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_dispersion_DA.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91afaac3d0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=plot_dispersion_convenience('DA', dispersion_df, movie_corpus, smoother=st.smoothing.mean_isotonic.MeanIsotonic())\n",
    "fn = f'movie_dispersion_DA.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now examine the residual of the dispersions relative to the expected values as estimated by the non-parametric curves.\n",
    "\n",
    "### DA Redidual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scattertext/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_dispersion_DA_residual.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91aa0fc4d0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=plot_dispersion_convenience('DA', dispersion_df, movie_corpus, smoother=st.smoothing.mean_isotonic.MeanIsotonic(), plot_residual=True)\n",
    "fn = f'movie_dispersion_DA_residual.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KLD is too focused on low-frequency terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_dispersion_KLD_residual.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91a9d8ef90>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=plot_dispersion_convenience('KL-divergence', dispersion_df, movie_corpus, smoother=st.smoothing.lowess.Lowess(), plot_residual=True)\n",
    "fn = f'movie_dispersion_KLD_residual.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_dispersion_DP_residual.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91a9ec59d0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=plot_dispersion_convenience('DP', dispersion_df, movie_corpus, smoother=st.smoothing.lowess.Lowess(), plot_residual=True)\n",
    "fn = f'movie_dispersion_DP_residual.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
