{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, json, re, sys, time, warnings, datetime, glob\n",
    "sys.path.insert(0, '../scattertext/')\n",
    "\n",
    "import scipy.stats as ss    \n",
    "import pandas as pd\n",
    "import scattertext as st\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Rotten Tomatoes Movie Review Data Set (Pang and Lee 2002)\n",
    "\n",
    "We parse each review with spaCy. On a 2018 Macbook Pro, this takes about 31 seconds. The progress bar tells us it has processed documents. Reviews include polarity (positive or negative) and the name of the movie being reviewed.  4,866 reviews are retained after filtering for plot descriptions.\n",
    "\n",
    "Data set is from http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "References:\n",
    "* Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan, Thumbs up? Sentiment Classification using Machine Learning Techniques, Proceedings of EMNLP 2002.\n",
    "\n",
    "* Bo Pang and Lillian Lee, A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts, Proceedings of ACL 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81724d1402b4242841c464d0971d663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5022 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_df = st.SampleCorpora.RottenTomatoes.get_data().assign(\n",
    "    category = lambda df: df.category.apply(\n",
    "        lambda x: {'rotten': 'Negative', 'fresh': 'Positive', 'plot': 'Plot'}[x]),\n",
    "    SpacyParse=lambda df: df.text.progress_apply(nlp)\n",
    ")[lambda df: df.category.isin(['Negative', 'Positive'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>SpacyParse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4866</td>\n",
       "      <td>4866</td>\n",
       "      <td>4866</td>\n",
       "      <td>4866</td>\n",
       "      <td>4866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>4863</td>\n",
       "      <td>156</td>\n",
       "      <td>4866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Positive</td>\n",
       "      <td>subjectivity_html/subj/2002/Abandon_2002.html</td>\n",
       "      <td>What we have is a character faced with the pos...</td>\n",
       "      <td>abandon</td>\n",
       "      <td>(Gaghan, captures, the, half, -, lit, ,, somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2455</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                       filename  \\\n",
       "count       4866                                           4866   \n",
       "unique         2                                            156   \n",
       "top     Positive  subjectivity_html/subj/2002/Abandon_2002.html   \n",
       "freq        2455                                             35   \n",
       "\n",
       "                                                     text movie_name  \\\n",
       "count                                                4866       4866   \n",
       "unique                                               4863        156   \n",
       "top     What we have is a character faced with the pos...    abandon   \n",
       "freq                                                    2         35   \n",
       "\n",
       "                                               SpacyParse  \n",
       "count                                                4866  \n",
       "unique                                               4866  \n",
       "top     (Gaghan, captures, the, half, -, lit, ,, somet...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a corpus object in Scattertext\n",
    "- The most straightforward way to visualize documents in Scattertext is to create a corpus object from a Pandas data frame. Each row corresponds to a single document, while columns indicate other data about each document. Scattertext has numerous classes available to represent corpora, but the one we will begin with is a `ParsedCorpus` generated by the `CorpusFromParsedDocuments` factory.\n",
    "- Typically, each document has a category about which Scattertext can generate various keyness metrics and visualizations. The columns containing the category and parse are passed as `parse_col` and `parsed_col`, respectively.\n",
    "- The corpus object contains feature representations of each document. These either be tokens that occur in the document (using a case-insensitive search) or other features, some of which are linked to character offsets or a searchable lexicon. These non-searchable features are called \"non_text\" features. For now, we'll generate simple token features. \n",
    "- To turn each document into a feature vector, we will use the `FlexibleNGrams` class. Here, we output all unigrams found in the spaCy parses, filtering out blank spaces. We also exclude terms used in less than 6 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_corpus = st.CorpusFromParsedDocuments(\n",
    "    movie_df,\n",
    "    category_col='category',\n",
    "    parsed_col='SpacyParse',\n",
    "    feats_from_spacy_doc=st.FlexibleNGrams(ngram_sizes=[1])\n",
    ").build().filter_out(\n",
    "    lambda x: len(x.strip()) < 1\n",
    ").remove_terms_used_in_less_than_num_docs(\n",
    "    threshold=6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of terms in corpus: 2083\n",
      "Number of reviews in corpus: 4866\n",
      "Number of categories in corpus: 2\n",
      "Categories in corpus: ['Negative', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of terms in corpus:\", unigram_corpus.get_num_terms())\n",
    "print(\"Number of reviews in corpus:\", unigram_corpus.get_num_docs())\n",
    "print(\"Number of categories in corpus:\", unigram_corpus.get_num_categories())\n",
    "print(\"Categories in corpus:\", unigram_corpus.get_categories())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics about terms in the corpus \n",
    "\n",
    "= We can retrieve the term-document matrix as a sparse matrix using the `get_term_doc_mat` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4866, 2083)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = unigram_corpus.get_term_doc_mat()\n",
    "tdm.todense().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics about terms in the corpus \n",
    "\n",
    "- We can use classes called `TermRanker`s to get term frequency statistics from each document. \n",
    "- N.B.\n",
    "    - Currently, only three are implemented, and the ones which rely on document size use feature counts found in the term-document matrix. \n",
    "    - This means that if >1-grams are present or features have been removed, these will provide inaccurate estimates of document size. Use caution when using these, but they may still yield interesting results.\n",
    "- The first and simplest is called the `AbsoluteFrequencyRanker`, where the sum of the number of terms in each category is returned. The `label_append` is a string concatenated to each category's name. The `label_append` is useful if other category-specific metrics will be added to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Count</th>\n",
       "      <th>Positive Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>2287</td>\n",
       "      <td>2351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>949</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>2148</td>\n",
       "      <td>2466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative Count  Positive Count\n",
       "term                                    \n",
       "captures               1               5\n",
       "the                 2287            2351\n",
       "half                  27              14\n",
       "-                    949             902\n",
       ",                   2148            2466"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.AbsoluteFrequencyRanker(unigram_corpus).get_ranks(label_append=' Count').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OncePerDocFrequencyRanker` ignores terms that occur in more than one document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Documents</th>\n",
       "      <th>Positive Documents</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1364</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>634</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>1366</td>\n",
       "      <td>1488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative Documents  Positive Documents\n",
       "term                                            \n",
       "captures                   1                   5\n",
       "the                     1364                1414\n",
       "half                      26                  13\n",
       "-                        634                 642\n",
       ",                       1366                1488"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.OncePerDocFrequencyRanker(unigram_corpus).get_ranks(label_append=' Documents').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DocLengthNormalizedFrequencyRanker` weights each term by its document percentage, i.e., \n",
    "\n",
    "$$\\mbox{weight}_{t,c} = \\sum_{\\mbox{doc } d \\ \\in \\mbox{category } c} \\frac{\\#(t, d)}{|d|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkessler/anaconda3/envs/py38/lib/python3.7/site-packages/scipy/sparse/base.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.true_divide(self.todense(), other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative Percentages</th>\n",
       "      <th>Positive Percentages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.298333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>115.924483</td>\n",
       "      <td>117.177789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>1.340761</td>\n",
       "      <td>0.711467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>50.754314</td>\n",
       "      <td>45.370685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>108.902535</td>\n",
       "      <td>123.622976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative Percentages  Positive Percentages\n",
       "captures              0.041667              0.298333\n",
       "the                 115.924483            117.177789\n",
       "half                  1.340761              0.711467\n",
       "-                    50.754314             45.370685\n",
       ",                   108.902535            123.622976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.DocLengthNormalizedFrequencyRanker(unigram_corpus).get_ranks(label_append=' Percentages').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom TermRanker\n",
    "\n",
    "We can implement our own term ranker by creating a subclass of `scattertext.termranking.TermRanker.TermRanker` or `st.TermRanker`. \n",
    "\n",
    "This custom ranker will return mean tf.idf scores for each document in a category. Note that the term frequencies are square-root scaled.\n",
    "\n",
    "The `TermRanker.get_term_doc_mat()` returns a document-row/term-column CSR sparse matrix, with values indicating the number of times a term appeared in that document.\n",
    "\n",
    "A data frame should be returned indexed on terms and with the index named \"term\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTFIDF(st.TermRanker):\n",
    "    def get_ranks(self, label_append: str=' mean tf.idf') -> pd.DataFrame:\n",
    "        sqrt_tf = np.sqrt(self.get_term_doc_mat())\n",
    "        idf = np.log(self._corpus.get_num_docs()/(tdm>0).sum(axis=0).A1)\n",
    "        tfidf = sqrt_tf.multiply(idf).tocsr()\n",
    "        y = self._corpus.get_category_ids()        \n",
    "        return pd.DataFrame({\n",
    "            cat+label_append : tfidf[y == cat_i, :].mean(axis=0).A1\n",
    "            for cat_i, cat \n",
    "            in enumerate(self._corpus.get_categories())\n",
    "        }).assign(\n",
    "            term = self._corpus.get_terms()\n",
    "        ).set_index('term')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative mean tf.idf</th>\n",
       "      <th>Positive mean tf.idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.013642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.397556</td>\n",
       "      <td>0.403445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>0.052877</td>\n",
       "      <td>0.026372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.416547</td>\n",
       "      <td>0.403839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.368237</td>\n",
       "      <td>0.403435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Negative mean tf.idf  Positive mean tf.idf\n",
       "term                                                \n",
       "captures              0.002778              0.013642\n",
       "the                   0.397556              0.403445\n",
       "half                  0.052877              0.026372\n",
       "-                     0.416547              0.403839\n",
       ",                     0.368237              0.403435"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MeanTFIDF(unigram_corpus).get_ranks().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting language difference between positive and negative reviews\n",
    "\n",
    "- Scattertext projects unigrams on a scatterplot based on the rank of their frequencies in each category. \n",
    "- The placement and color of each term are given in the `plot_df` data frame, where `Xpos` and `Ypos` indicate term coordinates ($\\in [0,1]^2$).\n",
    "- Scattertext attempts to label as many points as possible on the plot.\n",
    "- The ColorScore indicates which terms receive bluer (more positive) or more red (more negative) point colors. \n",
    "  - The score is based on the difference between the scaled category frequency ranks.\n",
    "  - Terms receiving the highest and lowest scores are labeled \"Top Newer\" and \"Top Older.\"\n",
    "- The unusual terms in the corpus (as judged by a set of general-purpose term frequencies) are displayed in the Characteristic column. \n",
    "- The newer function `dataframe_scattertext` function renders the scatter plot.\n",
    "- Clicking on a term displays its usage in context.\n",
    "- The get_heading(corpus) function returns the metadata text for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scattertext/scattertext/Scalers.py:247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  vec_ss = (vec_ss - vec_ss.min()) * 1. / (vec_ss.max() - vec_ss.min())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_denserank_unigrams.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff190402110>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_heading(corpus: st.ParsedCorpus):\n",
    "    return corpus.get_df().movie_name\n",
    "\n",
    "plot_df = st.AbsoluteFrequencyRanker(unigram_corpus).get_ranks(label_append='').assign(\n",
    "    X=lambda df: df.Positive,\n",
    "    Y=lambda df: df.Negative,\n",
    "    PosRank = lambda df: ss.rankdata(df.X, method='dense'),\n",
    "    NegRank = lambda df: ss.rankdata(df.Y, method='dense'),\n",
    "    Xpos=lambda df: st.scale(df.NegRank),\n",
    "    Ypos=lambda df: st.scale(df.PosRank),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero(df.Ypos - df.Xpos),\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': np.arange(0, 1, 0.01),\n",
    "    'y' :np.arange(0, 1, 0.01),\n",
    "})\n",
    "\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    unigram_corpus,\n",
    "    plot_df=plot_df,\n",
    "    category='Positive', \n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    width_in_pixels=1000, \n",
    "    ignore_categories=False,    \n",
    "    metadata=get_heading,\n",
    "    color_score_column='ColorScore',\n",
    "    left_list_column='ColorScore',\n",
    "    show_characteristic=False,\n",
    "    y_label='Positive Frequency Rank',\n",
    "    x_label='Negative Frequency Rank',\n",
    "    tooltip_columns=['PosRank', 'NegRank'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative'},\n",
    "    line_coordinates = line_df.to_dict('records'),   \n",
    ")\n",
    "\n",
    "fn = 'movie_denserank_unigrams.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the same action, but let's swap absolute frequencies for Mean TF.IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movie_mean_tf_idf_unigrams.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff1903e4050>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_heading(corpus: st.ParsedCorpus):\n",
    "    return corpus.get_df().movie_name\n",
    "\n",
    "plot_df = MeanTFIDF(unigram_corpus).get_ranks(label_append='').assign(\n",
    "    X=lambda df: df.Positive,\n",
    "    Y=lambda df: df.Negative,\n",
    "    PosRank = lambda df: ss.rankdata(df.X, method='dense'),\n",
    "    NegRank = lambda df: ss.rankdata(df.Y, method='dense'),\n",
    "    Xpos=lambda df: st.scale(df.NegRank),\n",
    "    Ypos=lambda df: st.scale(df.PosRank),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero(df.X - df.Y),\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': np.arange(0, 1, 0.01),\n",
    "    'y' :np.arange(0, 1, 0.01),\n",
    "})\n",
    "\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    unigram_corpus,\n",
    "    plot_df=plot_df,\n",
    "    category='Positive', \n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    width_in_pixels=1000, \n",
    "    ignore_categories=False,    \n",
    "    metadata=get_heading,\n",
    "    color_score_column='ColorScore',\n",
    "    left_list_column='ColorScore',\n",
    "    show_characteristic=False,\n",
    "    y_label='Positive Mean TF.IDF Rank',\n",
    "    x_label='Negative Mean TF.IDF Ranak',\n",
    "    tooltip_columns=['Positive', 'Negative'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative'},\n",
    "    line_coordinates = line_df.to_dict('records'),   \n",
    ")\n",
    "\n",
    "fn = 'movie_mean_tf_idf_unigrams.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Xpos</th>\n",
       "      <th>Ypos</th>\n",
       "      <th>ColorScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>captures</th>\n",
       "      <td>0.998378</td>\n",
       "      <td>1.001622</td>\n",
       "      <td>1.001622</td>\n",
       "      <td>0.998378</td>\n",
       "      <td>0.320782</td>\n",
       "      <td>0.679218</td>\n",
       "      <td>0.507622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.989773</td>\n",
       "      <td>1.010227</td>\n",
       "      <td>1.010227</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>0.376565</td>\n",
       "      <td>0.623435</td>\n",
       "      <td>0.548060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>half</th>\n",
       "      <td>1.005489</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>1.005489</td>\n",
       "      <td>0.274688</td>\n",
       "      <td>0.725312</td>\n",
       "      <td>0.442662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>1.001454</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>0.998546</td>\n",
       "      <td>1.001454</td>\n",
       "      <td>0.300840</td>\n",
       "      <td>0.699160</td>\n",
       "      <td>0.484807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.960460</td>\n",
       "      <td>1.039540</td>\n",
       "      <td>1.039540</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>0.566590</td>\n",
       "      <td>0.433410</td>\n",
       "      <td>0.685813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unfaithful</th>\n",
       "      <td>1.000045</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>1.000045</td>\n",
       "      <td>0.309979</td>\n",
       "      <td>0.690021</td>\n",
       "      <td>0.499534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyne</th>\n",
       "      <td>1.000437</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>0.999563</td>\n",
       "      <td>1.000437</td>\n",
       "      <td>0.307434</td>\n",
       "      <td>0.692566</td>\n",
       "      <td>0.495434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallace</th>\n",
       "      <td>1.001267</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>1.001267</td>\n",
       "      <td>0.302057</td>\n",
       "      <td>0.697943</td>\n",
       "      <td>0.486768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oleander</th>\n",
       "      <td>0.999200</td>\n",
       "      <td>1.000800</td>\n",
       "      <td>1.000800</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>0.315452</td>\n",
       "      <td>0.684548</td>\n",
       "      <td>0.503759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windtalkers</th>\n",
       "      <td>1.002096</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>0.997904</td>\n",
       "      <td>1.002096</td>\n",
       "      <td>0.296679</td>\n",
       "      <td>0.703321</td>\n",
       "      <td>0.478102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Negative  Positive         X         Y      Xpos      Ypos  \\\n",
       "term                                                                      \n",
       "captures     0.998378  1.001622  1.001622  0.998378  0.320782  0.679218   \n",
       "the          0.989773  1.010227  1.010227  0.989773  0.376565  0.623435   \n",
       "half         1.005489  0.994511  0.994511  1.005489  0.274688  0.725312   \n",
       "-            1.001454  0.998546  0.998546  1.001454  0.300840  0.699160   \n",
       ",            0.960460  1.039540  1.039540  0.960460  0.566590  0.433410   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "unfaithful   1.000045  0.999955  0.999955  1.000045  0.309979  0.690021   \n",
       "lyne         1.000437  0.999563  0.999563  1.000437  0.307434  0.692566   \n",
       "wallace      1.001267  0.998733  0.998733  1.001267  0.302057  0.697943   \n",
       "oleander     0.999200  1.000800  1.000800  0.999200  0.315452  0.684548   \n",
       "windtalkers  1.002096  0.997904  0.997904  1.002096  0.296679  0.703321   \n",
       "\n",
       "             ColorScore  \n",
       "term                     \n",
       "captures       0.507622  \n",
       "the            0.548060  \n",
       "half           0.442662  \n",
       "-              0.484807  \n",
       ",              0.685813  \n",
       "...                 ...  \n",
       "unfaithful     0.499534  \n",
       "lyne           0.495434  \n",
       "wallace        0.486768  \n",
       "oleander       0.503759  \n",
       "windtalkers    0.478102  \n",
       "\n",
       "[2083 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyness in Scattertext: Term Scorers\n",
    "\n",
    "- Given a corpus, we can produce scores and statistics for how associated features are to a particular category.\n",
    "- Subclasses of `CorpusBasedTermScorer` can produce these scores and use a `TermRanker` in the process.\n",
    "- We will look at some built-in term scorers and see how to write our own.\n",
    "- First, let's examine a simple term scorer, the smoothed log odds ratio, implemented in the `LogOddsRatioScorer` class.\n",
    "\n",
    "The log odds ratio, comparing a category $a$ against a category $b$, is defined as:\n",
    "\n",
    "$$ \\mbox{Log-Odds-Ratio}(\\mbox{term}_i, \\mbox{category}_a, \\mbox{category}_b) = \\log \\frac{\\#_{ai}}{|a| - \\#_{ai}} - \\log \\frac{\\#_{bi}}{|b| - \\#_{bi}} $$\n",
    "\n",
    "where $\\#_{\\mbox{category}, \\mbox{term index}}$ is the number of times a term occurred in a category, and $|\\mbox{category}|$ is the number of terms in a category.\n",
    "\n",
    "- Pseudo counts of a small $\\alpha$ (often 0.01) are added to each term count to prevent undefined values when a term does not appear in a category,\n",
    "\n",
    "- A single \"positive\" category and multiple \"negative\" categories are added to the TermScorer. By default, all categories which are not positive are considered as negative categories.\n",
    "\n",
    "We will first view the scores as a data frame, then plot them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative freq</th>\n",
       "      <th>Positive freq</th>\n",
       "      <th>Smoothed Log Odds Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boring</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.776894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seagal</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.651694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benigni</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.582684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pinocchio</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.508559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stale</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.428501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>touching</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jones</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haynes</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>riveting</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.357511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winning</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.437568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Negative freq  Positive freq  Smoothed Log Odds Ratio\n",
       "term                                                            \n",
       "boring                17              0                -9.776894\n",
       "seagal                15              0                -9.651694\n",
       "benigni               14              0                -9.582684\n",
       "pinocchio             13              0                -9.508559\n",
       "stale                 12              0                -9.428501\n",
       "...                  ...            ...                      ...\n",
       "touching               0             12                 9.357511\n",
       "jones                  0             12                 9.357511\n",
       "haynes                 0             12                 9.357511\n",
       "riveting               0             12                 9.357511\n",
       "winning                0             13                 9.437568\n",
       "\n",
       "[2083 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.LogOddsRatioScorer(\n",
    "    unigram_corpus,\n",
    "    constant=0.001\n",
    ").set_term_ranker(\n",
    "    term_ranker=st.AbsoluteFrequencyRanker\n",
    ").set_categories(\n",
    "    category_name='Positive',\n",
    "    not_category_names=['Negative']\n",
    ").get_score_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score-centered visualization\n",
    "\n",
    "- Alternatively, we can visualize various keyness metrics against term frequency. \n",
    "- We can use `dataframe_scattertext`, or `produce_frequency_explorer`, which is both more conscise at the expense of being and less customizable.\n",
    "- Points are colored by the term scores, with bluer points with higher scores and redder points with lower scors.\n",
    "- It takes the corpus, names of the positive and negative categories, and the list of negative categories (the `not_categories` parameter).\n",
    "- It includes a `minimum_term_frequency` threshold (you should typically set this to zero) and a `grey threshold` parameter, which gives an absolute value of range of scores to gery out. This is useful when the score ia p-value or z-score and a significance threshold is used.\n",
    "- Examining the plot, we can see that terms closely related to films, such as actors and directors score highly. These are mostly associated with movies which had exclusively positive or negative. \"Segal\" for example, appeared in all reviews for Half Past Dead, a movie which was panned in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"700\"\n",
       "            src=\"movies_log_odds_ratio_smoothed.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff18f475310>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    not_categories=['Negative'],\n",
    "    term_scorer=st.LogOddsRatioScorer,\n",
    "    term_ranker=st.AbsoluteFrequencyRanker,\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_log_odds_ratio_smoothed.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative: Cohen's $d$\n",
    "\n",
    "Cohen's $d$ computes an effect size for each term. An effect size is the number of pooled standard deviations which separate the category means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Negative',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.CohensD,\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_cohensd.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Negative',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.CohensD,\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_cohensd.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available term scorers:\n",
    "\n",
    "- `st.BetaPosterior` Beta Posterior (Bamman et al 2014) as reported by (Chang and McKeown, 2019).\n",
    "- `st.RelativeEntropy` Relative Entropy (Fankhauser et al 2014)\n",
    "- `st.BNSScorer` Bi-normal separation (Forman 2008)\n",
    "- `st.CohensD` Cohen's d; Hedges r, p-values and z-scores available in `CohensD.get_score_df`\n",
    "- `st.HedgesR` Hedge's r\n",
    "- `st.LogOddsRatio` Log odds ratio\n",
    "- `st.DeltaJSDivergenceScrorer` JS Divergence\n",
    "- `st.CraigsZetaScorer\n",
    "\n",
    "\n",
    "\n",
    "David Bamman, Jacob Eisenstein, and Tyler Schnoebelen.  GENDER IDENTITY AND LEXICAL VARIATION IN SOCIAL MEDIA. 2014.\n",
    "\n",
    "Serina Chang and Kathleen McKeown. Automatically Inferring Gender Associations from Language. EMNLP 2019\n",
    "\n",
    "Peter Fankhauser, Jorg Knappen, Elke Teich. Exploring and visualizing variation in language resources. LREC 2014.\n",
    "    \n",
    "George Forman. BNS feature scaling: an improved representation over tf-idf for svm text classification. CIKM 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.DeltaJSDivergenceScorer,\n",
    "    term_ranker=MeanTFIDF,\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_deltajsd.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class LogOddsRatioUniformativePriorScorer with abstract methods _set_scorer_args",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7f71fc280434>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_heading\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mminimum_term_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgrey_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/scattertext/scattertext/__init__.py\u001b[0m in \u001b[0;36mproduce_frequency_explorer\u001b[0;34m(corpus, category, category_name, not_category_name, term_ranker, alpha, use_term_significance, term_scorer, not_categories, grey_threshold, y_axis_values, frequency_transform, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mterm_scorer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterm_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0muse_non_text_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'use_non_text_features'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m         \u001b[0mterm_ranker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mterm_ranker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m     )\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/scattertext/scattertext/__init__.py\u001b[0m in \u001b[0;36m_initialize_term_scorer_if_needed\u001b[0;34m(category, corpus, neutral_categories, not_categories, show_neutral, term_scorer, use_non_text_features, term_ranker)\u001b[0m\n\u001b[1;32m    818\u001b[0m                                       use_non_text_features, term_ranker):\n\u001b[1;32m    819\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minherits_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CorpusBasedTermScorer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_scorer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mABCMeta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m         \u001b[0mterm_scorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minherits_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_scorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CorpusBasedTermScorer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_non_text_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class LogOddsRatioUniformativePriorScorer with abstract methods _set_scorer_args"
     ]
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Negative',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.LogOddsRatioUniformativePriorScorer,\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_lorups.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or just use the dense rank difference in the original chart\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Negative',\n",
    "    not_category_name='Negative',\n",
    "    term_scorer=st.RankDifferensceScorer(unigram_corpus),\n",
    "    metadata=get_heading,\n",
    "    minimum_term_frequency=0,\n",
    "    grey_threshold=0,\n",
    ")\n",
    "\n",
    "fn = 'movies_rank_diff.html'\n",
    "with open(fn, 'w') as of:\n",
    "    of.write(html)\n",
    "\n",
    "\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_corpus = unigram_corpus.recategorize(unigram_corpus.get_df()['movie_name'])\n",
    "\n",
    "dispersion = st.Dispersion(\n",
    "    movie_corpus,\n",
    "    use_categories=True\n",
    ")\n",
    "dispersion_df=dispersion.get_df().assign(\n",
    "    DA=dispersion.dp(),\n",
    "    X=lambda df: df.Frequency,\n",
    "    Xpos=lambda df: st.Scalers.log_scale(df.X),\n",
    "    Y=lambda df: df.DA,\n",
    "    Ypos=lambda df: st.Scalers.scale(df.Y)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_corpus = unigram_corpus.recategorize(unigram_corpus.get_df()['movie_name'])\n",
    "\n",
    "dispersion = st.Dispersion(\n",
    "    movie_corpus,\n",
    "    use_categories=True\n",
    ")\n",
    "dispersion_df=dispersion.get_df().assign(\n",
    "    DA=dispersion.dp(),\n",
    "    X=lambda df: df.Frequency,\n",
    "    Xpos=lambda df: st.Scalers.log_scale(df.X),\n",
    "    Y=lambda df: df.DA,\n",
    "    Ypos=lambda df: st.Scalers.scale(df.Y),\n",
    "    Expected=lambda df: st.smoothing.lowess.Lowess().fit(\n",
    "        np.array([df.X.values]).T,\n",
    "        df.Y.values\n",
    "    ).predict(np.array([df.X.values]).T).T[0],\n",
    "    Residual=lambda df: df.Ypos - st.scale(df.Y, df.Expected),\n",
    "    ColorScore=lambda df: 1 #st.Scalers.scale(df.DA)\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': dispersion_df.Xpos.values,\n",
    "    'y': dispersion_df.Expected.values,\n",
    "}).sort_values(by='x')\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    movie_corpus,\n",
    "    plot_df=dispersion_df,\n",
    "    metadata=get_heading,\n",
    "    ignore_categories=False,\n",
    "    x_label='Log Frequency',\n",
    "    y_label='DA',\n",
    "    y_axis_labels=['More Dispersion', 'Medium', 'Less Dispersion'],\n",
    "    color_score_column='ColorScore',\n",
    "    tooltip_columns=['Frequency', 'DA'],\n",
    "    header_names={'upper': 'Top DA', 'lower': 'Bottom DA'},\n",
    "    left_list_column='DA',\n",
    "    show_characteristic=False,\n",
    "    line_coordinates = line_df.to_dict('records')\n",
    ")\n",
    "\n",
    "fn = 'movie_dispersion.html'\n",
    "open(fn, 'w').write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "residual_df = dispersion_df.assign(\n",
    "    Y = lambda df: df.Residual,\n",
    "    Ypos = lambda df: st.Scalers.scale_center_zero(df.Y)\n",
    ")\n",
    "\n",
    "line_df = pd.DataFrame({\n",
    "    'x': residual_df.Xpos.values,\n",
    "    'y': 0.5,\n",
    "}).sort_values(by='x')\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',\n",
    "    plot_df=residual_df,\n",
    "    metadata=get_heading,\n",
    "    ignore_categories=False,\n",
    "    sort_doc_labels_by_name=True,\n",
    "    x_label='Log Frequency',\n",
    "    y_label='Residual: DA - E-hat[DA]',\n",
    "    y_axis_labels=['More Dispersion', 'Medium', 'Less Dispersion'],\n",
    "    color_score_column='ColorScore',\n",
    "    tooltip_columns=['Frequency', 'Residual'],\n",
    "    header_names={'upper': 'Lower than Expected', 'lower': 'More than Expected', 'right': 'Frequency'},\n",
    "    left_list_column='Residual',\n",
    "    right_order_column='Frequency',    \n",
    "    line_coordinates = line_df.to_dict('records'),\n",
    "    show_corpus_stats=False\n",
    ")\n",
    "\n",
    "fn = 'movie_dispersion_residual.html'\n",
    "open(fn, 'w').write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispersion_df=st.get_category_dispersion(\n",
    "    corpus=unigram_corpus,\n",
    "    corpus_to_parts=lambda corpus: corpus.get_df()['movie_name'],\n",
    "    metric='DA',\n",
    "    non_text=False\n",
    ")\n",
    "\n",
    "coordinates = st.Scalers.scale_jointly(\n",
    "    x=st.Scalers.log_scale(dispersion_df.Negative_DA + 0.01), \n",
    "    y=st.Scalers.log_scale(dispersion_df.Positive_DA + 0.01)\n",
    ")\n",
    "\n",
    "dispersion_df = dispersion_df.assign(\n",
    "    X=lambda df: df.Negative_DA,\n",
    "    Xpos=lambda df: coordinates.x,\n",
    "    Y=lambda df: df.Positive_DA,\n",
    "    Ypos=lambda df: coordinates.y,\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero(df.Y-df.X),\n",
    "    Frequency=lambda df: df.Positive_Frequency+df.Negative_Frequency\n",
    ")\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    unigram_corpus,\n",
    "    category='Positive',\n",
    "    category_name='Positive',\n",
    "    not_category_name='Negative',    \n",
    "    plot_df=dispersion_df,\n",
    "    metadata=get_heading,\n",
    "    ignore_categories=False,\n",
    "    x_label='Negative Log DA',\n",
    "    y_label='Positive Log DA',\n",
    "    y_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    x_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    color_score_column='ColorScore',\n",
    "    tooltip_columns=['Positive_DA', 'Negative_DA'],\n",
    "    header_names={'upper': 'Top Positive', 'lower': 'Top Negative', 'right': 'Frequency'},\n",
    "    left_list_column='ColorScore',\n",
    "    right_order_column='Frequency',    \n",
    ")\n",
    "\n",
    "fn = 'movie_pos_da_neg_da.html'\n",
    "open(fn, 'w').write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_corpus = unigram_corpus.remove_categories(['Negative']).recategorize(\n",
    "    lambda corpus: corpus.get_df()['movie_name']\n",
    ")\n",
    "\n",
    "plot_df = st.Dispersion(\n",
    "    positive_corpus, use_categories=True\n",
    ").get_adjusted_metric_df()\n",
    "\n",
    "plot_df = plot_df.assign(\n",
    "    X=lambda df: df.Frequency,\n",
    "    Xpos=lambda df: st.Scalers.log_scale(df.X),\n",
    "    Y=lambda df: df.Residual,\n",
    "    Ypos=lambda df: st.Scalers.scale_center_zero_abs(df.Residual),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero_abs(df.Residual),\n",
    ")\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    positive_corpus,\n",
    "    plot_df=plot_df,\n",
    "    metadata=get_heading,\n",
    "    unified_context=True,\n",
    "    ignore_categories=False,\n",
    "    show_corpus_stats=False,\n",
    "    x_label='Log Frequency',\n",
    "    y_label='Residual DA',\n",
    "    y_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    #x_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    color_score_column='ColorScore',\n",
    "    tooltip_columns=['Frequency', 'Residual'],\n",
    "    header_names={'upper': 'Top Residual', 'lower': 'Bottom Residual', 'right': 'Frequency'},\n",
    "    left_list_column='ColorScore',\n",
    "    right_order_column='Frequency',    \n",
    ")\n",
    "\n",
    "fn = 'movie_pos_residual.html'\n",
    "open(fn, 'w').write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_corpus = unigram_corpus.remove_categories(['Positive']).recategorize(\n",
    "    lambda corpus: corpus.get_df()['movie_name']\n",
    ")\n",
    "\n",
    "plot_df = st.Dispersion(\n",
    "    negative_corpus, use_categories=True\n",
    ").get_adjusted_metric_df()\n",
    "\n",
    "plot_df = plot_df.assign(\n",
    "    X=lambda df: df.Frequency,\n",
    "    Xpos=lambda df: st.Scalers.log_scale(df.X),\n",
    "    Y=lambda df: df.Residual,\n",
    "    Ypos=lambda df: st.Scalers.scale_center_zero_abs(df.Residual),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero_abs(df.Residual),\n",
    ")\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    negative_corpus,\n",
    "    plot_df=plot_df,\n",
    "    metadata=get_heading,\n",
    "    unified_context=True,\n",
    "    ignore_categories=False,\n",
    "    show_corpus_stats=False,\n",
    "    x_label='Log Frequency',\n",
    "    y_label='Residual DA',\n",
    "    y_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    #x_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    color_score_column='ColorScore',\n",
    "    tooltip_columns=['Frequency', 'Residual'],\n",
    "    header_names={'upper': 'Top Residual', 'lower': 'Bottom Residual', 'right': 'Frequency'},\n",
    "    left_list_column='ColorScore',\n",
    "    right_order_column='Frequency',    \n",
    ")\n",
    "\n",
    "fn = 'movie_neg_residual.html'\n",
    "open(fn, 'w').write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_df = st.Dispersion(\n",
    "    positive_corpus, use_categories=True\n",
    ").get_adjusted_metric_df()\n",
    "\n",
    "plot_df = plot_df.assign(\n",
    "    X=lambda df: df.Frequency,\n",
    "    Xpos=lambda df: st.Scalers.log_scale(df.X),\n",
    "    Y=lambda df: df.Residual,\n",
    "    Ypos=lambda df: st.Scalers.scale_center_zero_abs(df.Residual),\n",
    "    ColorScore=lambda df: st.Scalers.scale_center_zero_abs(df.Residual),\n",
    ")\n",
    "\n",
    "html = st.dataframe_scattertext(\n",
    "    positive_corpus,\n",
    "    plot_df=plot_df,\n",
    "    metadata=get_heading,\n",
    "    unified_context=True,\n",
    "    ignore_categories=False,\n",
    "    show_corpus_stats=False,\n",
    "    x_label='Log Frequency',\n",
    "    y_label='Residual DA',\n",
    "    y_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    #x_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n",
    "    color_score_column='ColorScore',\n",
    "    tooltip_columns=['Frequency', 'Residual'],\n",
    "    header_names={'upper': 'Top Residual', 'lower': 'Bottom Residual', 'right': 'Frequency'},\n",
    "    left_list_column='ColorScore',\n",
    "    right_order_column='Frequency',    \n",
    ")\n",
    "\n",
    "fn = 'movie_pos_residual.html'\n",
    "open(fn, 'w').write(html)\n",
    "IFrame(src=fn, width = 1300, height=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
